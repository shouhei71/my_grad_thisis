{\rtf1\ansi\ansicpg932\cocoartf1038\cocoasubrtf320
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset128 HiraKakuProN-W3;\f2\fswiss\fcharset0 ArialMT;
\f3\fnil\fcharset128 HiraMinProN-W3;\f4\fnil\fcharset0 AppleSymbols;}
{\colortbl;\red255\green255\blue255;}
{\info
{\author Shohei Okudera}}\paperw11900\paperh16840\margl1440\margr1440\vieww18000\viewh11120\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural

\f0\fs24 \cf0 ##############################\
# 
\f1 \'91\'b2\'98\'5f\'90\'b6\'82\'cc\'8f\'68\'91\'e8
\f0 101004\
##############################\
\
#
\f2\fs26  ICDE\
\
1.\
\uc0\u9633 title\
Personalized Web Search with Location Preferences\
\
\uc0\u9633 
\f1 abstruct\
 we propose a new web search personalization approach that captures the user\'81\'66s interests and preferences in the form of concepts by mining search results and their clickthroughs. we separate concepts into content concepts and location concepts, and organize them into ontologies to create an ontology-based, multi-facet (OMF) profile to precisely capture the user\'81\'66s content and location interests and hence improve the search accuracy. \'8e\'c0\'91\'95\'82\'b5\'82\'c4\'82\'dd\'82\'c4\'81\'41\'83\'78\'81\'5b\'83\'58\'83\'89\'83\'43\'83\'93\'82\'e6\'82\'e8\'82\'e0\'97\'c7\'82\'a2\'8c\'8b\'89\'ca\'82\'aa\'8f\'6f\'82\'bd\'81\'42\
\'81\'a0\'93\'fa\'96\'7b\'8c\'ea\
\'83\'8d\'83\'50\'81\'5b\'83\'56\'83\'87\'83\'93\'8f\'ee\'95\'f1\'82\'f0\'89\'c1\'96\'a1\'82\'b5\'82\'bd
\f2 Personalized Web Search
\f1 \'82\'f0\'92\'f1\'88\'c4\'82\'b7\'82\'e9\'81\'42\'83\'4e\'83\'47\'83\'8a\'81\'5b\'82\'c9\'91\'ce\'82\'b7\'82\'e9\'83\'86\'81\'5b\'83\'55\'82\'cc\'81\'75\'83\'52\'83\'93\'83\'65\'83\'93\'83\'63\'81\'76\'82\'c6\'81\'75\'83\'8d\'83\'50\'81\'5b\'83\'56\'83\'87\'83\'93\'81\'76(\'93\'c1\'82\'c9\'83\'82\'83\'6f\'83\'43\'83\'8b\'83\'54\'81\'5b\'83\'60\'82\'c5\'82\'cd\'8f\'64\'97\'76)\'82\'c9\'8a\'d6\'82\'b7\'82\'e9\'8b\'bb\'96\'a1\'82\'f0\'82\'e6\'82\'e8\'90\'b3\'8a\'6d\'82\'c9\'82\'c6\'82\'e7\'82\'a6\'82\'e9\'8c\'9f\'8d\'f5\'95\'fb\'96\'40\'82\'f0\'92\'f1\'88\'c4\'82\'b7\'82\'e9\'81\'42\'82\'dc\'82\'bd\'81\'41\'83\'4e\'83\'47\'83\'8a\'81\'5b\'81\'41\'83\'86\'81\'5b\'83\'55\'81\'5b\'82\'c9\'91\'ce\'82\'b5\'82\'c4\'81\'41\'81\'75\'83\'52\'83\'93\'83\'65\'83\'93\'83\'63\'81\'76\'82\'c6\'81\'75\'8f\'ea\'8f\'8a\'81\'76\'82\'cc\'8f\'64\'97\'76\'93\'78\'81\'41\'8b\'bb\'96\'a1\'82\'cc\'93\'78\'8d\'87\'82\'a2\'82\'cd\'88\'d9\'82\'c8\'82\'e9\'82\'aa\'81\'41\'82\'bb\'82\'ea\'82\'e0\'8d\'6c\'97\'b6\'82\'b7\'82\'e9\'82\'e6\'82\'a4\'82\'c8\'8c\'9f\'8d\'f5\'82\'cc\'8e\'64\'91\'67\'82\'dd\'82\'c5\'82\'a0\'82\'e9\'81\'42\'8e\'c0\'91\'95\'82\'b5\'82\'c4\'82\'dd\'82\'c4\'81\'41\'83\'78\'81\'5b\'83\'58\'83\'89\'83\'43\'83\'93\'82\'e6\'82\'e8\'82\'e0\'97\'c7\'82\'a2\'8c\'8b\'89\'ca\'82\'aa\'8f\'6f\'82\'bd\'81\'42\
\
\
(Experimental results show that OMF improves the precision significantly compared to the baseline\
Moreover, recognizing the fact that different users and queries may have different emphases on content and location information, we introduce the notion of content and location entropies to measure the amount of content and location information associated with a query, and click content and location entropies to measure how much the user is interested in the content and location information in the results. \
Accordingly, we propose to define personalization effectiveness based on the entropies and use it to balance the weights between the content and location facets. \

\f2 )\
\
\
\

\f1 2.\

\f2 \uc0\u9633 title\
\pard\pardeftab720\sl320\ql\qnatural

\f1 \cf0 The ORCHESTRA Collaborative Data Sharing System\
\pard\pardeftab720\sl320\ql\qnatural

\f2 \cf0 \uc0\u9633 
\f1 abstruct\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural
\cf0 Sharing structured data today requires standardizing upon a single schema, then mapping and cleaning all of the data. This results in a single queriable mediated data instance. However, for settings in which structured data is being collaboratively authored by a large community, e.g., in the sci- ences, there is often a lack of consensus about how it should be represented, what is correct, and which sources are au- thoritative. Moreover, such data is seldom static: it is frequently updated, cleaned, and annotated. The ORCHESTRA collaborative data sharing system develops a new architec- ture and consistency model for such settings, based on the needs of data sharing in the life sciences. In this paper we describe the basic architecture and implementation of the ORCHESTRA system, and summarize some of the open chal- lenges that arise in this setting.\
\'81\'a0\'93\'fa\'96\'7b\'8c\'ea\
\'8d\'5c\'91\'a2\'83\'66\'81\'5b\'83\'5e\'82\'f0\'8b\'a4\'97\'4c\'82\'b7\'82\'e9\'82\'bd\'82\'df\'82\'c9\'82\'cd\'81\'41\'88\'ea\'82\'c2\'82\'cc\'83\'58\'83\'4c\'81\'5b\'83\'7d\'82\'c9\'91\'ce\'82\'b5\'82\'c4\'95\'57\'8f\'80\'89\'bb\'82\'b7\'82\'e9\'82\'b1\'82\'c6\'82\'aa\'8d\'a1\'93\'fa\'95\'4b\'97\'76\'82\'c5\'82\'a0\'82\'e9\'81\'42\'82\'b5\'82\'a9\'82\'b5\'82\'c8\'82\'aa\'82\'e7\'81\'41\'91\'e5\'82\'ab\'82\'c8\'83\'52\'83\'7e\'83\'85\'83\'6a\'83\'65\'83\'42\'82\'c5\'8d\'5c\'91\'a2\'83\'66\'81\'5b\'83\'5e\'82\'f0\'8b\'ad\'92\'b2\'82\'b5\'82\'c4\'8d\'ec\'90\'ac\'82\'b7\'82\'e9\'8d\'db\'82\'c9\'82\'cd\'81\'41\'83\'66\'81\'5b\'83\'5e\'82\'f0\'82\'c7\'82\'cc\'82\'e6\'82\'a4\'82\'c9\'95\'5c\'8c\'bb\'82\'b7\'82\'e9\'82\'a9\'81\'41\'89\'bd\'82\'aa\'90\'b3\'82\'b5\'82\'a2\'82\'a9\'81\'41\'82\'c7\'82\'cc\'83\'5c\'81\'5b\'83\'58\'82\'aa\'90\'4d\'97\'8a\'90\'ab\'82\'aa\'82\'a0\'82\'e9\'82\'cc\'82\'a9\'82\'c8\'82\'c7\'82\'c9\'82\'c2\'82\'a2\'82\'c4\'81\'41\'83\'52\'83\'93\'83\'5a\'83\'93\'83\'54\'83\'58\'82\'aa\'8e\'e6\'82\'e7\'82\'ea\'82\'c4\'82\'a2\'82\'c8\'82\'a2\'82\'b1\'82\'c6\'82\'aa\'91\'bd\'82\'a2\'81\'42\'89\'e4\'81\'58\'82\'cd\'81\'41\'82\'bb\'82\'cc\'82\'e6\'82\'a4\'82\'c8\'8a\'c2\'8b\'ab\'82\'c9\'82\'a8\'82\'a2\'82\'c4\'83\'66\'81\'5b\'83\'5e\'88\'ea\'8a\'d1\'90\'ab\'82\'f0\'95\'db\'82\'c2\'82\'b1\'82\'c6\'82\'cc\'82\'c5\'82\'ab\'82\'e9\'81\'41\'83\'49\'81\'5b\'83\'50\'83\'58\'83\'67\'83\'58\'83\'89\'82\'c6\'96\'bc\'95\'74\'82\'bd\'8b\'a6\'92\'b2\'93\'49\'82\'c9\'83\'66\'81\'5b\'83\'5e\'82\'f0\'8b\'a4\'97\'4c\'82\'b7\'82\'e9\'83\'56\'83\'58\'83\'65\'83\'80\'82\'f0\'8e\'c0\'91\'95\'82\'b5\'82\'bd\'81\'42\'96\'7b\'98\'5f\'95\'b6\'82\'cd\'81\'41\'83\'49\'81\'5b\'83\'50\'83\'58\'83\'67\'83\'89\'82\'cc\'8d\'5c\'91\'a2\'82\'e2\'8e\'c0\'91\'95\'82\'c6\'81\'41\'8d\'a1\'8c\'e3\'82\'cc\'89\'db\'91\'e8\'82\'c9\'82\'c2\'82\'a2\'82\'c4\'8f\'71\'82\'d7\'82\'e9\'81\'42
\f2 \
\
\
\
\
3.\
\uc0\u9633 title\
Reliable Storage and Querying for Collaborative Data Sharing Systems\
\uc0\u9633 
\f1 abstruct\
The sciences, business confederations, and medicine urgently need infrastructure for sharing data and updates among collaborators\'81\'66 constantly changing, heterogeneous databases. The ORCHESTRA system addresses these needs by providing data transformation and exchange capabilities across DBMSs, combined with archived storage of all database versions. ORCHESTRA adopts a peer-to-peer architecture in which individual collaborators contribute data and compute resources, but where there may be no dedicated server or compute cluster.\
We study how to take the combined resources of ORCHESTRA\'81\'66s autonomous nodes, as well as PCs from \'81\'67cloud\'81\'68 services such as Amazon EC2, and provide reliable, cooperative storage and query processing capabilities. We guarantee reliability and correctness as in distributed or cloud DBMSs(
\f0 database management system
\f1 ), while also supporting cross-domain deployments, replication, and transparent failover, as provided by peer-to-peer systems. Our storage and query subsystem supports dozens to hundreds of nodes across different domains, possibly including nodes on cloud services.\
\
Our contributions include (1) a modified data partitioning substrate that combines cluster and peer-to-peer techniques, (2) an efficient implementation of replicated, reliable, versioned storage of relational data, (3) new query processing and indexing techniques over this storage layer, and (4) a mechanism for incrementally recomputing query results that ensures correct, complete, and duplicate-free results in the event of node failure during query execution. We experimentally validate query processing performance, failure detection methods, and the performance benefits of incremental recovery in a prototype implementation.\
\'81\'a0\'93\'fa\'96\'7b\'8c\'ea\
\'83\'4e\'83\'89\'83\'45\'83\'68\'83\'54\'81\'5b\'83\'72\'83\'58\'82\'cc\'82\'e6\'82\'a4\'82\'c9\'81\'41\'82\'a2\'82\'a9\'82\'c9\'83\'49\'81\'5b\'83\'50\'83\'58\'83\'67\'83\'89\'82\'cc\'8e\'a9\'97\'a7\'93\'49\'82\'c8\'83\'6d\'81\'5b\'83\'68\'82\'f0\'8c\'8b\'82\'d1\'82\'c2\'82\'af\'81\'41\'90\'4d\'97\'8a\'90\'ab\'81\'41\'8b\'a6\'92\'b2\'90\'ab\'82\'aa\'82\'a0\'82\'e9\'83\'58\'83\'67\'83\'8c\'81\'5b\'83\'57\'81\'41\'83\'4e\'83\'47\'83\'8a\'8f\'88\'97\'9d\'94\'5c\'97\'cd\'95\'94\'88\'ca\'82\'f0\'92\'f1\'8b\'9f\'82\'b7\'82\'e9\'82\'a9\'82\'f0\'8c\'a4\'8b\'86\'82\'b5\'82\'bd\'81\'42\'89\'e4\'81\'58\'82\'cc\'83\'58\'83\'67\'83\'8c\'81\'5b\'83\'57\'82\'c6\'83\'4e\'83\'47\'83\'8a\'81\'5b\'83\'54\'83\'75\'83\'56\'83\'58\'83\'65\'83\'80\'82\'cd\'83\'4e\'83\'89\'83\'45\'83\'68\'83\'54\'81\'5b\'83\'72\'83\'58\'8f\'e3\'82\'cc\'83\'6d\'81\'5b\'83\'68\'82\'e0\'8a\'dc\'82\'df\'81\'41\'90\'94\'8f\'5c\'81\'41\'95\'53\'82\'cc\'88\'d9\'82\'c8\'82\'e9\'83\'68\'83\'81\'83\'43\'83\'93\'8f\'e3\'82\'c9\'94\'7a\'92\'75\'82\'b3\'82\'ea\'82\'e9\'83\'6d\'81\'5b\'83\'68\'82\'cc\'8f\'e3\'82\'c5\'89\'d2\'93\'ad\'82\'b7\'82\'e9\'82\'b1\'82\'c6\'82\'aa\'8f\'6f\'97\'88\'82\'e9\'81\'42\
\
\
\
\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\ql\qnatural\pardirnatural
\cf0 \
\
\
4.\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural

\f2 \cf0 \uc0\u9633 title\
\pard\pardeftab720\sl320\ql\qnatural

\f1 \cf0 Optimal Load Shedding with Aggregates and Mining Queries\
\pard\pardeftab720\sl320\ql\qnatural

\f2 \cf0 \uc0\u9633 
\f1 abstruct\
 To cope with bursty arrivals of high-volume data, a DSMS has to shed load while minimizing the degradation of Quality of Service (QoS). In this paper, we show that this problem can be formalized as a classical optimization task from operations research, in ways that accommodate different requirements for multiple users, different query sensitivities to load shedding, and different penalty functions. Standard non-linear programming algorithms are adequate for non-critical situations, but for severe overloads, we propose a more efficient algorithm that runs in linear time, without compromising opti- mality. Our approach is applicable to a large class of queries including traditional SQL aggregates, statistical aggregates (e.g., quantiles), and data mining functions, such as k-means, naive Bayesian classifiers, decision trees, and frequent pattern discovery (where we can even specify a different error bound for each pattern). In fact, we show that these aggregate queries are special instances of a broader class of functions, that we call reciprocal- error aggregates, for which the proposed methods apply with full generality.\
Finally, we propose a novel architecture for supporting load shedding in an extensible system, where users can write arbitrary User Defined Aggregates (UDA), and thus confirm our analytical findings with several experiments executed on an actual DSMS.\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural
\cf0 \'81\'a0\'93\'fa\'96\'7b\'8c\'ea\
\'83\'6f\'81\'5b\'83\'58\'83\'67\'93\'49\'82\'c8\'83\'4e\'83\'47\'83\'8a\'82\'aa\'93\'9e\'92\'85\'82\'b5\'82\'bd\'82\'ab\'82\'bd\'82\'c6\'82\'ab\'82\'c9
\f3\b\fs17\fsmilli8966 \'81\'41
\f1\b0\fs26 \'90\'fc\'8c\'60\'8e\'9e\'8a\'d4\'82\'c5\'8e\'c0\'8d\'73\'82\'c5\'82\'ab\'81\'41\'8d\'c5\'93\'4b\'89\'bb\'82\'b3\'82\'ea\'8c\'f8\'89\'ca\'93\'49\'82\'c8\'83\'41\'83\'8b\'83\'53\'83\'8a\'83\'59\'83\'80\'82\'f0\'92\'f1\'88\'c4\'82\'b7\'82\'e9\'81\'42\
\'81\'48\'81\'48\
\pard\pardeftab720\sl320\ql\qnatural
\cf0 \
\
5.\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural

\f2 \cf0 \uc0\u9633 title\
\pard\pardeftab720\sl320\ql\qnatural

\f1 \cf0 Avoiding Bad Query Mixes to Minimize Client Timeouts Under Heavy Loads\
\pard\pardeftab720\sl320\ql\qnatural

\f2 \cf0 \uc0\u9633 
\f1 abstruct\
In three-tiered web applications, some form of admission control is required to ensure that throughput and response times are not significantly harmed during periods of heavy load. We propose Q-Cop, a prototype system for improving admission control decisions that considers a combination of the load on the system, the number of simultaneous queries being executed, the actual mix of queries being executed, and the expected time a user may wait for a reply before they or their browser give up (i.e., time out). \
\
Using TPC-W( transactional web e-Commerce benchmark) queries, Our results show that this approach makes more informed decisions about which queries to reject and as a result significantly reduces the number of requests that time out. Across the range of workloads examined an average of 47% fewer requests are unsuccessful than the next best approach.\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural
\cf0 \'81\'a0\'93\'fa\'96\'7b\'8c\'ea\
\'8e\'4f\'91\'77\'83\'45\'83\'46\'83\'75\'83\'41\'83\'76\'83\'8a\'83\'50\'81\'5b\'83\'56\'83\'87\'83\'93\'83\'59\'82\'c5\'82\'cc\'8a\'c7\'97\'9d\'90\'a7\'8c\'e4\'8c\'88\'92\'e8(\'95\'fb\'96\'40)\'82\'f0\'89\'fc\'91\'50\'82\'b7\'82\'e9\'82\'e6\'82\'a4\'82\'c8\'8e\'8e\'8d\'ec\'83\'56\'83\'58\'83\'65\'83\'80Q-Cop\'82\'f0\'92\'f1\'88\'c4\'82\'b7\'82\'e9\'81\'42Q-Cop\'82\'cd\'81\'41\'83\'56\'83\'58\'83\'65\'83\'80\'82\'c9\'82\'a9\'82\'a9\'82\'e9\'95\'89\'89\'d7\'82\'e2\'81\'41\'93\'af\'8e\'9e\'8e\'c0\'8d\'73\'82\'b3\'82\'ea\'82\'e9\'83\'4e\'83\'47\'83\'8a\'81\'5b\'82\'cc\'90\'94\'81\'41\'8e\'c0\'8d\'db\'82\'c9\'83\'7e\'83\'62\'83\'4e\'83\'58\'82\'b3\'82\'ea\'82\'e9\'83\'4e\'83\'47\'83\'8a\'81\'5b\'82\'cc\'90\'94\'81\'41\'83\'86\'81\'5b\'83\'55\'82\'aa\'83\'8a\'83\'76\'83\'89\'83\'43\'82\'f0\'91\'d2\'82\'c4\'82\'e9\'8e\'9e\'8a\'d4\'82\'c8\'82\'c7\'82\'f0\'8d\'6c\'97\'b6\'82\'b5\'82\'c4\'89\'d2\'93\'ad\'82\'b7\'82\'e9\'81\'42\'8e\'c0\'8c\'b1\'8c\'8b\'89\'ca\'82\'c5\'82\'cd\'81\'41\'8f\'5d\'97\'88\'82\'cc\'83\'56\'83\'58\'83\'65\'83\'80\'82\'cd\'81\'41Q-cop\'82\'cc\'83\'8a\'83\'4e\'83\'47\'83\'58\'83\'67\'95\'bd\'8b\'cf\'82\'c547\'83\'70\'81\'5b\'83\'5a\'83\'93\'83\'67\'88\'c8\'89\'ba\'82\'aa\'82\'a4\'82\'dc\'82\'ad\'8e\'c0\'8d\'73\'82\'b3\'82\'ea\'82\'c8\'82\'a9\'82\'c1\'82\'bd\'81\'42\
\
\
6.\
\'81\'a0title\
\pard\pardeftab720\ql\qnatural
\cf0 Reconciling while tolerating disagreement in collaborative data sharing\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural
\cf0 \'81\'a0abstract\
In many data sharing settings, such as within the biological and biomedical communities, global data consistency is not always attainable: different sites' data may be dirty, uncertain, or even controversial. Collaborators are willing to share their data, and in many cases they also want to selectively import data from others --- but must occasionally diverge when they disagree about uncertain or controversial facts or values. For this reason, traditional data sharing and data integration approaches are not applicable, since they require a globally consistent data instance. Additionally, many of these approaches do not allow participants to make updates; if they do, concurrency control algorithms or inconsistency repair techniques must be used to ensure a consistent view of the data for all users.In this paper, we develop and present a fully decentralized model of collaborative data sharing, in which participants publish their data on an ad hoc basis and simultaneously reconcile updates with those published by others. Individual updates are associated with provenance information, and each participant accepts only updates with a sufficient authority ranking, meaning that each participant may have a different (though conceptually overlapping) data instance. We define a consistency semantics for database instances under this model of disagreement, present algorithms that perform reconciliation for distributed clusters of participants, and demonstrate their ability to handle typical update and conflict loads in settings involving the sharing of curated data.\
\'81\'a0\'93\'fa\'96\'7b\'8c\'ea\
\'90\'b6\'95\'a8\'8a\'77\'81\'41\'90\'b6\'97\'9d\'8a\'77\'82\'cc\'83\'52\'83\'7e\'83\'85\'83\'6a\'83\'65\'83\'42\'82\'cc\'82\'e6\'82\'a4\'82\'c8\'91\'bd\'82\'ad\'82\'cc\'83\'66\'81\'5b\'83\'5e\'82\'f0\'8b\'a4\'97\'4c\'82\'b7\'82\'e9\'8a\'c2\'8b\'ab\'82\'c5\'82\'cd\'81\'41\'83\'4f\'83\'8d\'81\'5b\'83\'6f\'83\'8b\'82\'c5\'82\'cc\'83\'66\'81\'5b\'83\'5e\'88\'ea\'8a\'d1\'90\'ab\'82\'aa\'95\'db\'82\'bd\'82\'ea\'82\'c4\'82\'a2\'82\'c8\'82\'a2\'81\'42\'82\'bb\'82\'cc\'8a\'c2\'8b\'ab\'82\'c5\'8b\'a6\'92\'b2\'93\'49\'82\'c9\'83\'66\'81\'5b\'83\'5e\'82\'f0\'8b\'a4\'97\'4c\'82\'b7\'82\'e9\'8a\'ae\'91\'53\'82\'c9\'95\'aa\'8e\'55\'82\'b3\'82\'ea\'82\'bd\'83\'82\'83\'66\'83\'8b\'82\'f0\'94\'ad\'95\'5c\'82\'b7\'82\'e9\'81\'42\'82\'b1\'82\'cc\'83\'82\'83\'66\'83\'8b\'82\'c5\'82\'cd\'81\'41\'8e\'51\'89\'c1\'8e\'d2\'82\'cd\'83\'66\'81\'5b\'83\'5e\'82\'f0\'8f\'ea\'93\'96\'82\'bd\'82\'e8\'93\'49\'82\'c9\'8d\'58\'90\'56\'82\'f0\'91\'97\'90\'4d\'82\'b5\'81\'41\'93\'af\'8e\'9e\'82\'c9\'91\'bc\'82\'cc\'90\'6c\'82\'cc\'8d\'58\'90\'56\'82\'f0\'97\'5a\'8d\'87\'82\'b3\'82\'b9\'82\'e9\'81\'42\'8c\'c2\'81\'58\'82\'cc\'8d\'58\'90\'56\'82\'c9\'82\'cd\'83\'66\'81\'5b\'83\'5e\'82\'cc\'8b\'4e\'8c\'b9\'8f\'ee\'95\'f1\'82\'aa\'95\'74\'89\'c1\'82\'b3\'82\'ea\'82\'c4\'82\'a8\'82\'e8\'81\'41\'8f\'5c\'95\'aa\'82\'c8\'8c\'a0\'8c\'c0\'83\'89\'83\'93\'83\'4c\'83\'93\'83\'4f\'82\'cc\'82\'c2\'82\'a2\'82\'bd\'82\'e0\'82\'cc\'8d\'58\'90\'56\'82\'be\'82\'af\'82\'f0\'8e\'51\'89\'c1\'8e\'d2\'82\'cd\'8e\'f3\'82\'af\'8e\'e6\'82\'e9\'82\'b1\'82\'c6\'82\'aa\'82\'c5\'82\'ab\'82\'e9\'81\'42\'83\'66\'83\'82\'82\'f0\'8d\'73\'82\'a2\'81\'41\'93\'54\'8c\'5e\'93\'49\'82\'c8\'8d\'58\'90\'56\'82\'e2\'81\'41\'83\'52\'83\'93\'83\'74\'83\'8a\'83\'4e\'83\'67\'95\'89\'89\'d7(?)\'82\'c9\'91\'ce\'8f\'88\'82\'b7\'82\'e9\'94\'5c\'97\'cd\'82\'f0\'8a\'6d\'82\'a9\'82\'df\'82\'bd\'81\'42\
\
\
In this paper, we develop and present a fully decentralized model of collaborative data sharing, in which participants publish their data on an ad hoc basis(\'8f\'ea\'93\'96\'82\'bd\'82\'e8\'93\'49\'82\'c9) and simultaneously reconcile updates with those published by others. Individual updates are associated with provenance(\'8b\'4e\'8c\'b9) information, and each participant accepts only updates with a sufficient authority ranking, meaning that each participant may have a different (though conceptually overlapping) data instance. We define a consistency semantics for database instances under this model of disagreement, present algorithms that perform reconciliation for distributed clusters of participants, and demonstrate their ability to handle typical update and conflict loads in settings involving the sharing of curated data.\
\

\f0\fs24 #
\f2\fs26  SOCC\
\
7.\
\uc0\u9633 title
\f0\fs24 \
Making Cloud Intermediate Data Fault-Tolerant
\f4 \

\f2\fs26 \uc0\u9633 
\f1 abstruct\
Parallel dataflow programs generate enormous amounts of distributed data that are short-lived, yet are critical for completion of the job and for good run-time performance. We call this class of data as intermediate data. This paper is the first to address intermediate data as a first-class citizen, specifically targeting and minimizing the effect of run-time server failures on the availability of intermediate data, and thus on performance metrics such as job completion time. We propose new design techniques for a new storage system called ISS (Intermediate Storage System), implement these techniques within Hadoop, and experimentally evaluate the resulting system. Under no failure, the performance of Hadoop augmented with ISS (i.e., job completion time) turns out to be comparable to base Hadoop. Under a failure, Hadoop with ISS outperforms base Hadoop and incurs up to 18% overhead compared to base no-failure Hadoop, depending on the testbed setup.\
\
\
\
\
\pard\pardeftab720\sl320\ql\qnatural
\cf0 \
}