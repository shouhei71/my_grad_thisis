<<< 最新版  >>>================================================================================= ●●● 概要 ●●●Amazon Dynamo、Cassandra をはじめとした単一故障点がなく、負荷が自動的に分散される 非集中型のクラウドストレージが普及しつつある。このような非集中なクラウドストレージに おいて、任意のノードからデータを保持する担 当ノードにリクエストを到達させるためには、 各ノードが他のノードを把握する必要がある。  特に、クライアントが接続したノードから担当 ノードに直接、リクエストを送るクラウドスト レージでは、 全ノードがシステム全体の最新の状態を保持する必要があり、整合性を保つこと が難しい。	  そこで、Gossip Protocol をベースとしたメ ンバーシップ管理を行うプロトコルが取り入れ られ、効率よく通信を行うことが可能である。	 一方、このようなメンバーシップ管理もスケ ーラビリティを制約する要因の一つとなりうる。	この管理方法では、すべてのノードで定期的に 通信が発生するので、ノード台数が増えるにつ れ、総通信量が増えるのである。よって、フロ ントエンド(例えばストレージであれば、デー タの読み書き処理。)	の処理効率つまり、アベ イラビリティを下げると考えられる。		  しかしながら、非集中型のクラウドストレー ジにおいて、この管理を行う処理がどれくらい の通信負荷をもたらすのかといったことは知られていない。	 そこで本研究では、Gossip  Protocol を用い る Cassandra を対象として、ノード台数に応じ てシステム全体の通信負荷がどのように変化す るのかを計測・考察する。	 計測の結果、システム全体で発生する通信量は、ノード台数をｎとしたとき、O(n^2)でスケールすることを確認した。  ●●● 第一章 序論 ●●●(全国大会の「はじめに」をベースにかく。以下は全国大会のものを切り貼りした。)◇1.1本研究の背景[例1]クラウド型の分散システムが流行っっている。(あちら側の居力な計算環境を利用してサービスを提供。)ビジネスレベルで言うと、Amazon EC2 とか、Windows azureとか企業が提供し、個人レベルでもEbenoteとかはやってますよね。クラウド型の分散システム構造をとることで、クライアントからの大量のリクエストをさばくことができる。しかしながら、一般にシステム全体のスループットを上げるのに、クラウドを構成するマシンの台数を増やせばいいといういうわけではない。ノードを追加したからと言って、期待通りにスループットが向上しないことあることが過去の研究で紹介している。これは、スループットが上昇したときに、ボトルネックとなってしますような部位がシステムに存在することに起因する。[例2.]近年、クラウドストレージ流行っています！大量のデータをさばいている。⇒クラウドストレージに求められている(要求されている)のは、安定して(噛み砕いて)、増え続ける大量のデータを処理すること。⇒そのためには、ボトルネックとなる部分がある。対応しなきゃ・安定して処理するためのボトルネックとは、クラウドを構成するマシンの故障である。ノード台数が多いほど、マシンの故障する確率はあがる。故障は常にあるものと考えなければならない。故障があっても、システム全体としては故障していない！ボトルネックをつくらない。・増え続ける大量のデータを処理することのボトルネックとなるためには、負荷が集中する場所をつくらないことである。[例3.]近年、ネットワークを通じて計算資源を利用するクラウドコンピューティングが流行している。その中でも、ペタバイト級の大量のデータを保存するストレージタイプのクラウドに注目が集まっている。クラウドストレージの必要要件として、1.)サービスを安定的に提供すること、2.)増加し続ける大量のデータを効率よく処理することの２つが挙げられる。。(この要件を満たすには、システムにボトルネックとなる部位を作らないことが必要である。)1.)サービスを安定的に継続するのためには、機器の一部が故障しても、システムの外側からは、故障していないように見えなければならない。一方、クラウドのように大量のノードで構成されるシステムにおいて故障は常である。そこで、故障が起きている状況をあらかじめ想定したシステムが必要である。2.)増加し続ける大量のデータを効率よく処理するためには、ノードの台数に題してスループットがスケールアウトできるアーキテクチャを採用することである。(その中でも特に注目を集めているのが、 Amazon Dynamo、Cassandra をはじめとした非集中型のクラウドストレージである。非集中型のクラウドストレージの特徴は、構成するすべてのノードが対等の機能をもつ、すなわちクラスタ内でメンバーシップ管理などのタスクを一任される特殊なマシンがいない、システムを構成するクラウドである。非集中型の利点は、単一故障点がないことである。つまり、クラスタを構成するマシンが故障したとしても、システムの外からは正常に動作しているように視えることである。二つめは、負荷が自動的に分散されることである。これは、どのノードも同じ処理を行えることから、処理を分散して行うことが可能であることである。一方、マシン間の通信、連携、特に、故障感知を自分でやらなきゃいけないので、コスト、とくに通信がかさむというデメリットがある。)->そこで、特に注目を集めているのが、 Amazon Dynamo、Cassandra をはじめとした非集中型クラウドストレージである。非集中型クラウドストレージとは、構成するすべてのノードが対等の機能をもつクラウドストレージのことである。非集中型クラウドストレージの一つ目の大きな利点は、単一故障点がないことである。単一故障点とは、故障するとシステム全体が故障してしまう部位のことである。非集中型にはこのような部位はなく、安定したサービスを提供することにつながる。二点目は、負荷が自動的に分散されることである。これは、スケールアウトできるアーキテクチャであることを指している。その一方、メンバーシップ管理などを各ノードで行う必要がある。このような非集中なクラウドストレージにおいて、任意のノードからデータを保持する担当ノードにリクエストを到達させる(以後、ルーティングと呼ぶ)ためには、各ノードが他のノードを把握する(以後、経路情報の管理と呼ぶ)必要がある。ルーティングの方針として大きく分けて、２つのバリエーションがある。担当ノードにリクエストを届けるまでに、別のノードを経由することを認めるか認めないかである。前者のルーティング方式をマルチホップ、シングルホップと呼ぶ。(マルチホップの利点としては、経路情報の管理コストが低いことである。これは、) 特に、シングルホップ方式のクラウドストレージでは、全ノードがシステム全体の最新の状態を保持する必要があり、整合性を保つことが難しい。 例えば、もし古い情報をもとにルーティングを行い、誤って別の担当ノードにリクエストを送信しまった場合、リクエストは適切に処理されないことになる。 そこで、Gossip Protocol をベースとしたメンバーシップ管理を行うプロトコルが取り入れられ、全ノードがシステム全体の最新の状態を保持することが可能である。Gossip Protocolとは、ソーシャルネットワーク で見られる噂(ゴシップ)の伝搬をモデルとしたアルゴリズムである。◇1.2本研究の目的非集中型のクラウドストレージにてGossip Protocol をベースとしたメンバーシップ管理を行うプロトコルが取り入れられ、全ノードがシステム全体の最新の状態を保持することが可能である。一方、このようなメンバーシップ管理もスケーラビリティを制約する要因の一つとなりうる。この管理方法では、すべてのノードで定期的に通信が発生するので、ノード台数が増えるにつれ、総通信量が増えるのである。よって、ストレージのメインタスクであるread/write処理効率つまり、アベイラビリティを下げると考えられる。しかしながら、非集中型のクラウドストレージにおいて、この管理を行う処理がどれくらいの通信負荷をもたらすのかといったことは知られていない。そこで本研究では、Gossip Protocol を用いる Cassandraを対象として、ノード台数に応じてシステム全体の通信負荷がどのように変化するのかを計測・考察する。◇1.3本研究の成果Gossip Protocol を用いる Cassandraを対象として、ノード台数に応じたシステム全体の通信量を計測した。その結果、ノード台数をｎとして、通信量はO(n^2)でスケールすることがわかった。また、結果から、クラスタ設計時に、Gossip Protocol ベースのメンバーシップ管理による通信量を見積もることができる。(さらに、今回の計測方法は、Cassandra以外のソフトウェアでも実行出来る)(    1.通信量の測定方法を紹介した。    2.gossip-baseのプロトコルで発生する通信量はO(n^2)でスケールする。    3.クラスタ設計時の通信量を見積もることができる。)◇1.4本研究の構成  第二章では、研究背景とし分散システム(クラウド)におけるメンバーシップ管理アルゴリズムとその問題点を指摘する。  続く第三章では、Cassandraノードで発生する通信負荷の測定手法を説明する。第四章では、クラスタ上での通信負荷の測定実験を行う。   ●●● 第二章 研究背景 ●●●◇2.1 大規模分散システムとは？...定義、一般的な特徴を述べる。最後に集中型(?)、非集中型の切り口から説明。(もしくは、クラウドストレージを大枠にする？)◇2.2 集中型(?)とは....◇◇2.2.1 その特徴は？...◇◇2.2.2 代表的なメンバシップ管理プロトコルを紹介。--プロトコルA----特徴----利点と問題点--プロトコルB----特徴----利点と問題点--プロトコルC----特徴----利点と問題点◇◇2.2.3 実装しているソフトウェアの紹介--実装A(hadoopとか？)--実装B(....)◇2.3 非集中型とは....◇◇2.3.1 その特徴は？...◇◇2.3.2 代表的なメンバシップ管理プロトコルを紹介。--プロトコルA(gossip)----特徴----利点と問題点--プロトコルB(flodding?)----特徴----利点と問題点--プロトコルC----特徴----利点と問題点◇◇2.3.3 実装しているソフトウェアの紹介--実装A(amazon)....--実装B(Cassandra)....◇◇2.4 通信量の観点から評価が知られていない...(私が調べることになった目的について述べる。) ●●● 第三章  測定手法 ●●●実験はCassandraで行った。◇3.1 Cassandraの概要    ...◇3.2 Cassandraの軽量化    1.データ部分のプログラムの改変    2.設定ファイルのパラメータ調整など◇3.3 実験シナリオ    1.実験環境         ・Cassandra 0.6.6         ・ OS: Linux 2.6.35.10-74.fc14.x86_64         ・Java 仮想マシン: Java SE 6 Update 21         ・CPU: 2.40 GHz Xeon E5620×2         ・ メモリー: 32GB RAM         ・ ネットワーク: 1000BASE-T    2.計測方法について説明◇3.4 通信量の推定について、    ・マシン間の通信から全体の通信量を推定できることを説明(グラフを使おう) ●●● 第四章  実験・評価 ●●●◇ 4.1予備実験◇◇ 4.1.1予備実験(1)120台のCassandra Nodesを立ち上げて推測するときに、実際のマシン数に依存せずに、通信量が推定できそうなことを示しておく。TypeA:120 cassandra nodes on 10 machinesTypeB:120 cassandra nodes on 2 machinesとし、TypeA,TypeBの実験から推測される通信量がほぼ一致することを確認。◇◇ 4.1.2予備実験(2?)seed数を変更したときの通信量の変化について(必要ない？)◇ 4.2 本実験例のグラフの表示 + グラフをフィッティングしたら...の関数になりました。◇4.3 評価◇◇ 4.3.1 １台あたりの通信量1.どのように通信量がスケールしていくか？◇◇ 4.3.2 システム全体の限界とは？一般的には議論するのは難しいので、クラスタの構成ごとに議論する。◇◇◇Type Aの場合(データセンター三つある場合)-0.データセンター内通信領域、データセンター外通信領域-1.構成の説明-2.各機器での通信量の見積もり-3.ボトルネックの場所で限界となるのはどこか？◇◇◇Type Bの場合(データセンター一つで構成する場合)..(同上)◇◇◇Type cの場合(ネットワーク1000base-Tのような切り口でもいけないか？)..(同上)◇◇◇まとめ-1.それぞれのタイプで限界を予測できた。-2.gossipと各構成との相性を通信量の観点から評価。◇◇ 4.3.3 二次関数的に通信量が増大していく理由ノードの台数をnとして、・数式X: (総通信量) = Order(n^2)数式Xが妥当である理由について考察する。◇◇◇1.Cassandraが使用しているGossip Protocolをベースとしたメンバーシップ管理について説明。(実装依存の部分も多いので)...◇◇◇2.数式から説明する------------------------------------------------------------------------------------------------------------------(総通信量) = (１台あたりの通信量) * (ノード台数)(ノード台数) = n(１台あたりの通信量) = (１秒あたりのgossip通信する回数) * (一回あたりのgossip通信にかかる通信量)＊「gossip通信」とは、一対一で経路情報を交換する通信のことです。(今後適切な言い回しに置き換えます。)(１秒あたりのgossip通信する回数) = 1,<- if 安定時なら(一回あたりのgossip通信にかかる通信量) = Order(n)よって・数式X: (総通信量) = Order(n^2)は妥当。まとめ、-安定時には、(１秒あたりのgossip通信する回数) = 1なので、Cassandra独自という意味合いはあまりなく、よりGossip一般的なデータといえそう。-------------------------------------------------------------------------------------------------------------------------- ●●● 第五章 関連研究 ●●●・分散システムのメンバーシップ管理について通信量の観点から調べたという論文をサーチし載せる◇5.1 論文A    ... ●●● 第六章 結論 ●●●◇5.1 まとめ    1.通信量の測定方法を紹介した。    2.gossip-baseのプロトコルで発生する通信量はO(n^2)でスケールする。    3.クラスタ設計時の通信量を見積もることができる。◇5.2 今後の課題    1.gossip protocol関連         -ルーターのフラップやチャーン状態の時の通信量を計測         -通信量と適切な経路情報が伝搬しているのかという二つの切り口でgossipを評価する    2.Gossip Protocol以外のメンバーシップ管理を行うプロトコルの通信量を調べること ●●● 謝辞 ●●●   .. ●●● 参考文献 ●●●    ..=================================================================================<<< 過去メモ  >>>================================================================================= ●●● 第一章 序論 ●●●(全国大会の「はじめに」をベースにかく。以下は全国大会のものを切り貼りした。)◇1.1本研究の背景 Amazon Dynamo、Cassandra をはじめとした 単一故障点がなく、負荷が自動的に分散される非集中型のクラウドストレージが普及しつつある。このような非集中なクラウドストレージにおいて、任意のノードからデータを保持する担当ノードにリクエストを到達させるためには、各ノードが他のノードを把握する必要がある。 特に、クライアントが接続したノードから担当ノードに直接、リクエストを送るクラウドストレージでは、全ノードがシステム全体の最新の状態を保持する必要があり、整合性を保つことが難しい。そこで、Gossip Protocol をベースとしたメンバーシップ管理を行うプロトコルが取り入れられ、効率よく通信を行うことが可能である。一方、このようなメンバーシップ管理もスケーラビリティを制約する要因の一つとなりうる。この管理方法では、すべてのノードで定期的に通信が発生するので、ノード台数が増えるにつれ、総通信量が増えるのである。よって、フロントエンド(例えばストレージであれば、データの読み書き処理。)の処理効率つまり、アベイラビリティを下げると考えられる。◇1.2本研究の目的しかしながら、非集中型のクラウドストレージにおいて、この管理を行う処理がどれくらいの通信負荷をもたらすのかといったことは知られていない。そこで本研究では、Gossip Protocol を用い るCassandraを対象として、ノード台数に応じてシステム全体の通信負荷がどのように変化するのかを計測・考察する。◇1.3本研究の成果    1.通信量の測定方法を紹介した。    2.gossip-baseのプロトコルで発生する通信量はO(n^2)でスケールする。    3.クラスタ設計時の通信量を見積もることができる。◇1.4本研究の構成    .... ●●● 第二章 研究背景 ●●●◇2.1 大規模分散システムとは？...定義、一般的な特徴を述べる。最後に集中型(?)、非集中型の切り口から説明。(もしくは、クラウドストレージを大枠にする？)◇2.2 集中型(?)とは....◇◇2.2.1 その特徴は？...◇◇2.2.2 代表的なメンバシップ管理プロトコルを紹介。--プロトコルA----特徴----利点と問題点--プロトコルB----特徴----利点と問題点--プロトコルC----特徴----利点と問題点◇◇2.2.3 実装しているソフトウェアの紹介--実装A(hadoopとか？)--実装B(....)◇2.3 非集中型とは....◇◇2.3.1 その特徴は？...◇◇2.3.2 代表的なメンバシップ管理プロトコルを紹介。--プロトコルA(gossip)----特徴----利点と問題点--プロトコルB(flodding?)----特徴----利点と問題点--プロトコルC----特徴----利点と問題点◇◇2.3.3 実装しているソフトウェアの紹介--実装A(amazon)....--実装B(Cassandra)....◇◇2.4 通信量の観点から評価が知られていない...(私が調べることになった目的について述べる。) ●●● 第三章  測定手法 ●●●実験はCassandraで行った。◇3.1 Cassandraの概要    ...◇3.2 Cassandraの軽量化    1.データ部分のプログラムの改変    2.設定ファイルのパラメータ調整など◇3.3 実験シナリオ    1.実験環境         ・Cassandra 0.6.6         ・ OS: Linux 2.6.35.10-74.fc14.x86_64         ・Java 仮想マシン: Java SE 6 Update 21         ・CPU: 2.40 GHz Xeon E5620×2         ・ メモリー: 32GB RAM         ・ ネットワーク: 1000BASE-T    2.計測方法について説明◇3.4 通信量の推定について、    ・マシン間の通信から全体の通信量を推定できることを説明(グラフを使おう) ●●● 第四章  実験・評価 ●●●◇ 4.1予備実験◇◇ 4.1.1予備実験(1)120台のCassandra Nodesを立ち上げて推測するときに、実際のマシン数に依存せずに、通信量が推定できそうなことを示しておく。TypeA:120 cassandra nodes on 10 machinesTypeB:120 cassandra nodes on 2 machinesとし、TypeA,TypeBの実験から推測される通信量がほぼ一致することを確認。◇◇ 4.1.2予備実験(2?)seed数を変更したときの通信量の変化について(必要ない？)◇ 4.2 本実験例のグラフの表示 + グラフをフィッティングしたら...の関数になりました。◇4.3 評価◇◇ 4.3.1 １台あたりの通信量1.どのように通信量がスケールしていくか？◇◇ 4.3.2 システム全体の限界とは？一般的には議論するのは難しいので、クラスタの構成ごとに議論する。◇◇◇Type Aの場合(データセンター三つある場合)-0.データセンター内通信領域、データセンター外通信領域-1.構成の説明-2.各機器での通信量の見積もり-3.ボトルネックの場所で限界となるのはどこか？◇◇◇Type Bの場合(データセンター一つで構成する場合)..(同上)◇◇◇Type cの場合(ネットワーク1000base-Tのような切り口でもいけないか？)..(同上)◇◇◇まとめ-1.それぞれのタイプで限界を予測できた。-2.gossipと各構成との相性を通信量の観点から評価。◇◇ 4.3.3 二次関数的に通信量が増大していく理由ノードの台数をnとして、・数式X: (総通信量) = Order(n^2)数式Xが妥当である理由について考察する。◇◇◇1.Cassandraが使用しているGossip Protocolをベースとしたメンバーシップ管理について説明。(実装依存の部分も多いので)...◇◇◇2.数式から説明する------------------------------------------------------------------------------------------------------------------(総通信量) = (１台あたりの通信量) * (ノード台数)(ノード台数) = n(１台あたりの通信量) = (１秒あたりのgossip通信する回数) * (一回あたりのgossip通信にかかる通信量)＊「gossip通信」とは、一対一で経路情報を交換する通信のことです。(今後適切な言い回しに置き換えます。)(１秒あたりのgossip通信する回数) = 1,<- if 安定時なら(一回あたりのgossip通信にかかる通信量) = Order(n)よって・数式X: (総通信量) = Order(n^2)は妥当。まとめ、-安定時には、(１秒あたりのgossip通信する回数) = 1なので、Cassandra独自という意味合いはあまりなく、よりGossip一般的なデータといえそう。-------------------------------------------------------------------------------------------------------------------------- ●●● 第五章 関連研究 ●●●・分散システムのメンバーシップ管理について通信量の観点から調べたという論文をサーチし載せる◇5.1 論文A    ... ●●● 第六章 結論 ●●●◇5.1 まとめ    1.通信量の測定方法を紹介した。    2.gossip-baseのプロトコルで発生する通信量はO(n^2)でスケールする。    3.クラスタ設計時の通信量を見積もることができる。◇5.2 今後の課題    1.gossip protocol関連         -ルーターのフラップやチャーン状態の時の通信量を計測         -通信量と適切な経路情報が伝搬しているのかという二つの切り口でgossipを評価する    2.Gossip Protocol以外のメンバーシップ管理を行うプロトコルの通信量を調べること ●●● 謝辞 ●●●   .. ●●● 参考文献 ●●●    ..================================================================================= 返信 転送