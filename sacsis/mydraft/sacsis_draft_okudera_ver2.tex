\documentclass[techrep]{ipsjpapers}
\bibliographystyle{ipsjunsrt.bst}
\usepackage{graphicx}


%\checklines	% 行送りを確認する時に使用
\begin{document}%{
% 和文表題
\title{非集中型クラウドストレージのスケーラビリティ評価}
% 英文表題
\etitle{A Scalability Study of A Decentralized Cloud Storage}
% 所属ラベルの定義
\affilabel{TIT}{東京工業大学\\Tokyo Institute of Technology}
% 和文著者名
\author{奥寺 昇平\affiref{TIT}\and
	中村 俊介\affiref{TIT}\and
	長尾 洋也\affiref{TIT}\and
	首藤 一幸\affiref{TIT}}
	
% 英文著者名
\eauthor{Shohei Okudera\affiref{TIT}\and
	Shunsuke Nakamura\affiref{TIT}\and
	Hiroya Nagao\affiref{TIT}\and
	Kazuyuki Shudo\affiref{TIT}}


% 連絡先（投稿時に必要．製版用では無視される．）
\contact{奥寺 昇平\\
	〒277-0831 千葉県柏市根戸464-13\\
	TEL: 04-(7133)-6556\qquad FAX: 04-(7133)-6556\\
	email: shouhei71@gmail.com}

% 和文概要
\begin{abstract}
非集中なクラウドストレージにおいて、任意のノードからデータを保持する担当ノードにリクエストを到達させるためには、各ノードが他のノードを把握する必要がある。特に、クライアントが接続したノードから担当ノードに直接リクエストを送るクラウドストレージでは、全ノードがシステム全体の最新の状態を保持する必要があり、システムの整合性を保つことが難しい。
そこで、gossipプロトコルをベースとしたメンバーシップ管理により効率よく通信を行うことが可能である。
一方、このようなメンバーシップ管理もスケーラビリティを制約する要因の一つとなりうる。この管理方法では、すべてのノードで定期的に通信が発生するので、ノード台数が増えるにつれ、総通信量が増えるのである。よって、フロントエンド(例えばストレージであれば、データの読み書き処理。)の処理効率つまり、アベイラビリティを下げると考えられる。しかしながら、非集中型のクラウドストレージにおいて、この管理を行う処理がどれくらいの通信負荷をもたらすのかといったことは知られていない。
そこで本研究では、gossipプロトコルを用いるクラウドストレージCassandraを対象として、ノード台数に応じてシステム全体の通信負荷がどのように変化するのかを計測・考察する。計測の結果、システム全体で発生するgossipの通信量は、ノード台数を$n$としたとき、O($n^2$)となることを確認した。定量的にクラウドストレージのgossipの通信量を計測できた。
\end{abstract}

% 英文概要
\begin{eabstract}
Abstract in English
\end{eabstract}

% 表題などの出力
\maketitle

%}{

% 本文はここから始まる
\section{はじめに}
分散システムには高い可動性が必要とされる。特にクラウドのような大規模な環境においては、急激に増加する負荷やネットワーク分断や部分故障といった問題に対しても
迅速に対応し、常に稼動し続けるような安定性・信頼性が求められる。

分散システムの可用性を確保する戦略\cite{TC}としてスケールアップ、スケールアウトの二つの戦略がある。
スケールアップとはシステムを構成する各マシン(のCPUやメモリ)の高機能化、高性能化を図ることで、システム全体の性能をスケールさせることを目的とした戦略である。
従来はこの戦略でシステムの性能向上が図られてきたが、費用に見合った性能向上には限界がある。
%そこで、google をはじめとしてシステムをスケールアウトさせる戦略をとるようになった。

一方、スケールアウトとは、マシン一台あたりの性能を上げるのではなく、安価な商用マシンを並べて並列処理を行うことで、可用性を確保するというと戦略である。
スケールアウトでは、一台あたりのマシンが安いため、スケールアップ戦略をとった場合と比べ、
費用を押さえて高いパフォーマンスを引き出すことができる。
その一方で、システム全体のノードのどれかが常に故障頻度が高くなるという問題がある。
スケールアウトによるスケーラビリティ確保の戦略では、マシンの数が増加するほど、システムでマシンやスイッチなどのハードウェアの故障が発生する確率は増加する。つまりシステム全体での平均故障間隔(MTBF)が非常に短くなってしまうのである。
%例えば、各マシンの1秒あたりの故障 する確率がp = 0 .001、マシンの台数を1000 とする。
%この時、1秒あたりシステムで故障が起きる確率は p=0.63 に跳ね上がる。
そこで、ハードウェアは常に故障するということを前提としたシステムの仕組みづくりが必要となる。

故障を前提とした分散システムで特に重要な機能は、故障したマシンに接続する他のマシンから故障を検知する仕組みである。
またシステムの整合性を保つためには、各マシンが検知するだけでなく、互いにその故障検知の情報を通信しあうことで、システム全体としての合意を取らなければならない。一方で、特にクラウドストレージにおいては、故障検知によるネットワーク、CPUなどのリソース消費は、控えばければならない。クラウドストレージでは、データの読み書きがメインのタスクであるからである。非集中なクラウドストレージの代表的な故障検知にgossipプロトコルが挙げられる。しかしながら、非集中なクラウドストレージにおいて、この管理を行う処理がどれくらいの通信負荷をもたらすのかといったことは知られていない。
そこで本研究では、gossipプロトコルが非集中なクラウドストレージでもたらす通信負荷を評価した。

%故障検知はマシンが故障している事実を直接検出したマシン以外のマシンにも伝えることである。
%その機能がなければ、個々のマシンで故障検知を行うことになり効率が悪く、システムの可用性が下がってしまう。

本章の構成は以下のとおりである。
２章で研究背景として、故障情報の伝播について説明し、
３章で関連研究として、クラウド環境でgossipプロトコルをベースにしたマルチキャストの評価\cite{CLON}について触れる。
４章で故障検知の代表的なアルゴリズムであるgossipプロトコルに焦点を当てる。
５章で非集中なクラウドストレージの一つであるCassandra\cite{Cassandra}について説明し、
６章でCassandraの軽量化と測定法について説明する。
７章で通信量測定の実験、評価を行い、
８章で論文をまとめる。

\section{研究背景}
故障した情報を他のノードに伝搬する方法には、すべてのノードに直接伝搬を行う全対全型、近接するノードにだけに伝える近傍型、ランダムで選んだノードだけ伝達するランダム型がある。
全対型は、故障を伝搬する時間は早いが、すべてのノードと通信が発生するのでスケーラビリティを確保できない。
また近傍型では、ネットワークの局所性を意識するので、通信のパフォーマンスは改善される一方で、新規ノードの追加、離脱時に近傍ノードを再設定しなければならないことやネットワーク情報を管理しなければならないという欠点がある。
ランダム型の代表的な伝搬アルゴリズムには、gossipプロトコルが挙げられる。
gossipプロトコルとは、ソーシャルネットワークで見られる噂 (ゴシップ) の伝搬をモデルとしたアルゴリズムである。
gossipプロトコルを利用して、検知した故障の情報を他のマシンに効率よく伝達することが可能である。近年Cassandraをはじめとしたクラウドストレージの故障検知にgossipプロトコルを応用したアルゴリズムが採用されており、メンバーシップ管理が行われている。
しかしながら、故障検知はメインのプロセスではない。
特にクラウドストレージにおいてのメインのプロセスは、データの読み書きを行うことであり、
故障検知はあくまでバックグラウンドのプロセスとして扱われる。バックグラウンドの処理がリソースを消費し、メインのデータ読み書きプロセスに大きな影響を与えるようであってはいけない。
すなわち、故障検知は計算資源や使用するネットワークバンド幅が限られている環境で実現されることが求められる。
しかしながら、クラウドストレージにおいては、gossipが及ぼす影響については、明確化されていない。
\if0
これらの問題を解決するために、gossipを応用したさまざまなプロトコルが提案されている。
例えば[参照１]では、クラウド環境を想定して、MTBFが非常に短いアンダーレイネットワークを考慮したオーバレイネットワークを構築し、局所的な通信が多く発生するように工夫した。ネットワークリソース資源の消費を押さえて故障検知を行っている。しかしながら、非集中な環境については、〇〇である。
\fi
%しかしながら、クラウドストレージにおいては、gossipが及ぼす影響については、明確化されていない。
%このような故障検知に求められる指標には、一貫性、パフォーマンス、動的な環境、スケーラビリティなど様々がある。
そこで我々は、クラウドストレージに適用されているgossipプロトコルにおいて通信量がノード数に対してどのように増加していくのかを実測し、
その特性について評価と考察を行った。
また実アプリであるYahoo! Cloud Serving Benchmark(YCSB)\cite{YCSB}を実行しデータ読み書きを
行った時の通信量の変化についても、実験・考察を行った。

\section{関連研究}\label{sec:Enum}\label{sec:item}
関連研究として、クラウド環境でgossipプロトコルをベースにしたマルチキャストを提案し評価した論文について紹介する。一般にグローバルで接続されたデータセンターから構成されるクラウドコンピューティングのインフラで起きているようなコストが高くリソース制約があるリンクが存在する。基本的なgossipプロトコルは、剛健で信頼性のあるデータ伝搬に対してスケールするアプロ地である一方、このようなクラウド環境においては、その冗長性がから、リンクとノードに高いリソース消費を引き起こす。そこで著者は、局所的なリンクを優先するオーバレイを構築し、局所を考慮して伝搬を行うことで、制約のあるリンク間でのトラフィックを減少させることができた。

本研究との関連は、分散システムで実ノードを立ち上げてgossipプロトコルベースのトラフィックを評価しているところである。しかしながら、我々は非集中なクラウドストレージに焦点を当てること、またマルチキャストではなく我々は故障検知を目的にしている点が異なる。

\section{gossipプロトコル}
gossipプロトコルとは、ソーシャルネットワークで見られる噂(ゴシップ)の伝搬をモデルとしたアルゴリズムである。
gossipプロトコルを利用して、検知した故障の情報を他のマシンに効率よく伝達することが可能である。
ノードp、qが存在し両者で情報交換を行うときと考える。gossipプロトコルを情報の伝搬方法によって三つのカテゴリーに分類することができる。\cite{Survey}
\begin{figure*}[t]
\includegraphics[width=16cm,scale=2]{img/gossip_gray.eps}
\caption{gossipプロトコル}
\end{figure*}

\begin{itemize}
\item A. Pull型のアプローチ\\
ノードpが持っている情報をノードqに送信し、ノードqの情報を更新する。
\item Push型のアプローチ\\
ノードpはノードqに情報のダイジェストを送信する。
ダイジェストを受け取ったノードqは必要な更新箇所だけをノードｐに送り返し、ノードｐは更新は行う。
\item Pull\&Push型のアプローチ\\
pull型のgossipと似ている。違いは、ノードqがノードpに更新箇所を送るときに、ノードｑのダイジェストを知らせることである。ノードｐはダイジェストを見て、ノードｑの情報も更新させる。
\end{itemize}
ここでは、Pull\&Push型を応用したプロトコル、Scuttlebutt\cite{EfficientReconciliationan}について詳しく説明する。

Scuttlebuttとは、分散システムでイベンチュアリーコンシステンシーに各メンバーが保持する情報を融合をするためのプロトコルの一つである。
Pull\&Push型アプローチを採用している。
特に、使用できるネットワーク帯域幅、CPUサイクルが限定されているときを想定している。
つまり、使用するネットワーク帯域幅を抑えるためにあるMTU(Message Transfer Unit)が決められていると仮定して、MTUのサイズの中で情報を融合できるように工夫し送信を行うのである。
具体的には、更新する情報に優先順位をつけて必要な情報だけを相手に伝搬させることで、システムの整合性を保ちつづ、ネットワーク帯域幅の消費を抑えた情報融合を可能にする。
通信手順について説明する。
メンバーの集合を$P = \{p,q,...\}$とし、各メンバーがマッピング$\sigma \in S = K \rightarrow (V \times N)$にモデル化された状態を保持している。ここで、$K$はキーのセット、$V$は値のセット、$N$は有限の順序付けられたバージョン番号の集合を表している。
$\sigma(k) = (v,n)$は、キー$k$が値vと、バージョン番号$v$にマップすることを意味している。　また最近のマッピングほどバージョン番号が大きい。
メンバーの状態は変更があり、またすべてのノードで複製化され保持している状況を考える。
そこでノードｐが保持する各メンバーのマッピングを$u_p$:P $\rightarrow$ Sとモデル化する。

メンバーの状態の更新を考える。メンバーpは、$u_p(p)$に対する更新のみが行えて、$u_q(p),p \neq q$に対してはgossipを通じて間接的にしか更新することができない。
%gossipプロトコルでの更新には、マージ・融合オペレータである$ \Theta $を使用しS内の二つの状態から新しい状態を生み出す。 \sigma_1(k)= (v_1 , n_1)$のセマンティクスは、
Scuttlebuttにおいての$u_p(p)$に対する更新では、一度に一つのキーに対する更新のみが可能であり、更新したキーに対するバージョンは、ｐが保持するマッピングの中のバージョン($max(\sigma_p)$)よりも大きな値に更新する規則がある。メンバーpとメンバーq
における更新では、$u_p(r)$に対する更新つまり融合では、バージョンが大きいキーの値で更新される。
$\sigma_1(k) = (v_1,n_1)$と$\sigma_2(k) = (v_2,n_2)$が融合し、$\sigma$が生成されるとする。
$n_1 >  n_2$であれば$\sigma = (v_1,n_1)$、そうでなければ$\sigma = (v_2,n_2)$となる。
ここで、ある特定のメンバー$p$が持つキー$k$,値$v$,バージョン$n$のタプルを$delta$を名付ける。
%アンチエントロピープロトコルは、マージ・融合オペレータである$ \Theta $を使用し、新しい状態を生み出す。$\sigma = \sigma_1 \Theta  \sigma_2$は以下を意味している。
%$ \sigma_1(k)= (v_1 , n_1)$
%キーに対する更新はあるキー$k$を更新する時は、二つのに対してバージョンが新しい値として更新後となる。

Scuttlebuttでは以下のように通信が行われる。
\begin{enumerate}
\item メンバー$p$が保持する各メンバーについてmappingの中で一番新しいバージョンだけ($\{(r,max(u_p(r))| r \in P )\}$)をメンバー$q$に送信する。
\item 同様に、メンバー$q$が保持する各メンバーについてmappingの中で一番新しいバージョンだけ($\{(r,max(u_q(r))| r \in Q )\}$)をメンバー$p$に送信する。
\item 上のようなダイジェストを受信したメンバー$q$は、下で定義している$\Delta^{p \rightarrow q} _{scuttle}$をメンバー$q$に送信する。
\item 3.と同様に、メンバーpから$\Delta^{q \rightarrow p} _{scuttle}$をメンバー$p$に送信する。
\begin{eqnarray}
\Delta^{p \rightarrow q} _{scuttle} = \{(r,k,v,n) | u_p(r)(k) = (v,n)\nonumber \\
\land   n > max(u_q(r)))\}\nonumber
\end{eqnarray}
すなわち、$\Delta^{p \rightarrow q} _{scuttle} = \{(r,k,v,n) | u_p(r)(k) = (v,n)$とは、あるメンバｒについてメンバー$q$がまだ更新していないキーの$delta$ということである。
\end{enumerate}
このようにはじめに、各メンバーに対する最大のバージョン番号をダイジェストとして通信することで、無駄な通信を省略することができる。
さらにMTUが存在するときには、手順3.手順4.ですべての更新情報を送信することはできない。
そこでバージョンが小さい$deltas$に優先順位をつけて更新の選択を決定することになる。
この選択により、システムの整合性を保ちつつ効率的な通信が可能になる。


\section{Cassandra}
Apache Cassndraは、Facebook社によって開発され、Apache Projectとしてオープンソース化されたクラウドストレージである。\cite{CassandraWiki}
複数のデータセンタ上に分散して配置された数百ノードで構成されることを想定しており、
高い可用性と単一故障点を持たない非集中な分散モデルが大きな特徴である。
このような大規模な環境では平均故障間隔は非常に短く、故障検知が重要である。
\subsection{メンバーシップ管理}
Cassandraを構成する各ノードは、リング上ID空間に配置される。
各ノードは、クラスタに参加しているすべてのメンバーをgossipにより把握する。
また、新規ノード追加時には、指揮するノードに予めシステム内の最初にコンタクトを取るノード(これをseedと呼ぶ)の情報を設定しておき、そのメンバーに新規に参加することを伝えた後で、クラスタに加わる。
メンバーシップ管理は、上述したgossipプロトコルであるScuttlebuttをベースに行っている。
ここでは、Scuttlebuttを使用した情報交換をgossip通信とする。
具体的には、以下の手順に沿って毎秒情報交換が行われる。
\begin{enumerate}
\item STEP1:もし他の生存しているノードが存在したら、ランダムで生存しているノードを選択してゴシップ通信を行う。
\item STEP2:生存ノードと到達できないノードの数に応じたある確率によって、ランダムで到達できないノードにgossip通信を行う。
\item STEP3:STEP1でゴシップ通信を行ったノードがseedではなかったとき、あるいはseedノードの数より生存しているノードが少ないときには、生存ノード、seed,到達不可のノードの数に応じたある確率でランダムでseedにgossip通信を行う。
\end{enumerate}
Cassandraノードはこの方式で毎秒1-3回のgossip通信を行っている。
\section{Cassandraの軽量化と測定手法}\label{sec:ITEM}
\subsection{Cassandraの軽量化}
実験にあたって物理リソースの都合上、1台あたり複数の Cassandra ノー ドを起動する必要があった。
デフォルトの設定では、１ノードのCassandra起動するためにデータを全く保持していない状態で、スレッド数が130、メモリー使用領域が120M程度とリソースを多く消費する。
また複数ノードでクラスタを構成した時にさらにリソースが消費される。リソースの消費を抑えるために、Cassandraデータ保持部分のプログラムの改変と、設定パラメータのチューニングを行った。
\subsubsection{プログラムの改変}
Cassandraは、データを保持していない状態であってもシステム管理のためのテーブルを保持する必要があり、メモリー使用量域がかさむ。この点を踏まえメモリー使用領域を減らすためにプログラムに改変を加える。\\
gossipプロトコルの通信量を測定する実験では、実データがどのようなものかは関係がない。そこで、実際のデータを保存するのではなくデータサイズだけを保管するように変更した。
%
%その結果メモリー使用量域が減った。クラスタを5台構成した直後に、平均150M - >130Mの変化があった。
%(具体的に数値を実験せよ！
%・実際データをいれていないので、削減は微々たるものであること
%・Localのマック上のデータは残っていない！
%・クラスターを構成して測定すること(構成しないと値はほとんど変わらない。)
%)
\subsubsection{パラメータの調整}
\begin{itemize}
\item JVM最大ヒープサイズの制限を変更\\
CassandraはJVM上で動作する。多数台起動するために、JVM最大ヒープサイズの制限を1Gから160Mに変更した。
%この変更でCassandraノード起動時のメモリが120Mから89Mに減少した。
\item 設定ファイルのパラメータ調整\\
設定ファイルでにて、同時読み込みを許す最大値、同時書き込みを許す最大値を制限することで
スレッド数を減らした。
\end{itemize}
また、これらのパラメータの調整は、gossipプロトコルの通信量を測定する実験では、直接関わらないパラメータであることに留意する。この調整により、１マシンあたりCassandraを最大65ノードまで起動することができた。
%このパラメータは,Cassandra読み込みで使用するスレッド数に直結するので、この数を32 - > 2 ,132 - > 2と減らした。この値は、Cassandraが食らうたーgossipプロトコルの通信量を測定する実験では、直接関わらないパラメータであるので数値を改変しても問題はない。このパラメータは,Cassandraで使用するスレッド数に直結するので、この数を32 - > 2 ,132 - > 2と減らした。この値は、Cassandraが食らうたーgossipプロトコルの通信量を測定する実験では、直接関わらないパラメータであるので数値を改変しても問題はない。２台起動してクラスタを構成したときの各マシンのスレッド数が121 ->  85に減少した

\subsection{測定手法}
非集中型クラウドストレージのスケーラビリティ評価するために以下の実験を行った。
\begin{itemize}
\item 実験1:gossipプロトコルの通信量の測定
\item 実験2:データ読み書きの通信量の測定
\end{itemize}

\subsubsection{実験1:gossipの通信量の測定}
実験1ではgossipの通信量の測定を行った。実験シナリオは、マスターとなるマシンを１台とワーカーとなるマシンを１０台を用意した。ワーカーマシンをNode1,Node2,...Node20と名付ける。マスターの役割は、通信量計測の開始・終了、Cassandraノードの起動,計測した記録の解析をワーカーに指示すること、最終的な通信量の推定を行うである。一方、ワーカーの役割は、通信量の計測、Cassandra ノー ドを起動すること、通信量の解析である。また、1台あたり複数のCassandraノードを立ち上げる必要がある。Cassandraノードの立ち上げ方は、30 秒ごとに、1台あたり 10 ノードの Cassandra を一度に起動し、これを目指す台数に達成するまで続ける。最初の Cassandra ノードを起動した瞬間から各マシンで10 分間の通信量を計測した。\\
計測後に各マシンで通信量を解析し、マスターとなるマシンに解析結果を送信する。マスターは、送られて通信量から合計値を出し、Cassandraで発生する通信量の推定を行う。\\
マスター、ワーカーで実行するプログラムは、シェルスクリプトでプログラムを書き、各ワーカーへの指示は、GXPを使用して制御した。GXPとは、同じコマンドを多数のホストで並列に実行するためのジョブスケジューラのことである。また、パケット情報の解析には、java,R,シェルスクリプトを使った。\\

\subsubsection{実験2:データ読み書きの通信量の測定}
実験2ではアプリケーションを用いてデータの読み書きを行ったときの通信量の測定を行った。
実験シナリオは、マスターとなるマシンを１台とワーカーとなるマシンを5台を用意し、実験１と同様の手順でCassandraの起動、通信量の測定を行った。\\
データを読み書きするアプリケーションには、Yahoo! Cloud Serving Benchmark(YCSB)を使用した。YCSBはYahoo! Researchが開発したクラウドストレージ用のベンチマークのことである。
\subsubsection{計測方法について}
実験１、実験２の計測にあたっていくつか工夫した共通の点を紹介する。
\begin{itemize}
\item ユーザー,プロセスのシステムリソース制約を外す\\
通常のオペレーションでは、１ユーザに共有のシステムリソースを占有されないように管理されている。具体的には、１ユーザが同時に実行出来るプロセス数、ファイル・ディスクリプタの数や、ユーザーが実行するプロセスにおいて、仮想メモリーの使用領域、物理メモリーの使用領域などが制限される。

上述したようにCassandraノードの実行には、メモリー使用量域が大きく、使用するスレッド数が多い。我々の実験環境では、数台のクラスタを構成するだけで１ノードあたりスレッド数が130程度必要であり、クラスタを構成するノード数が増加するとさらに比例していく。linuxのデフォルトの設定では、１ユーザが同時に実行出来るプロセス数は1024であるので、Cassandraノードを７台までしか起動できなかった。そこで、linuxのユーザーリソースを決める設定ファイルを編集し、１ユーザーのリソース制限、１プロセスのリソース制限を緩和した。その結果、多数台の起動が可能になった。
%\item NFSを利用した書き込みをできるだけ控える\\
%概して一度に多数ノードを起動するときは、実行ファイルを共通にして起動することが多い。すなわち、NFS上に共通の実行スクリプトを保存し、実行時に読み込むことが多い。しかしながら、一度に非常に多数のNFSを通じた読み込みが発生すると、上手くアクセス出来ないことがある。そこで、各マシンのローカル上に実行ファイルを保管し、起動時にそのファイルを読み込むようにした。
\item IPエイリアシングを利用し、プライベートネットワークを構築\\
Cassandraのメンバー管理では、IPアドレスでメンバーを認識する。つまり、今回の実験ように１マシンあたり複数ノードのCassandraを立ち上げようとすると、不都合が生じる。\\
そこで、IPエイリアシングを使用して仮想アドレスを作成し、Cassandraノードごとに割り振ることにした。その結果、同じマシン上に立ち上がったCassandraマシン同士の差異が明らかになり、不整合が起きなくなった。\\
さらに、通信量の測定の際にはノイズを防がないといけない。ノイズとは、Cassandraノード以外から要求されるリクエストのことである。具体的には、ARPやsshなどのパケットのことである。これらのパケットを誤って計測してしまうことを避けるために、IPエイリアスリングを行うと同時に、プライベートネットワークを構築した。このネットワークに参加しているのは、Cassandraノードだけである。よって、プライベートネットワーク内で飛び交うパケットのみを取得することが簡単にできる。\\
具体的には、10.20.0.0/16のネットワークを構築した。さらにCassandraノードが物理的にどのマシン上で起動しているかを判別しているために、実マシン(Node11,Node12,...,Node20)上のノード番号$n$を使用し、Node[$n$]上で起動するマシンに仮想的に10.20.$n$.0/24なるサブネットを設けた。例えば、実マシンNode19で起動するCassandraノードに割り当てられる仮想アドレスは、10.20.19.$x$ ($1< x < 254$)となる。
\item tcpdumpの使用\\
通信量の測定は、tcpdumpを使用した。上述したように、Cassandraノード同士のやりとりはプライベートネットワーク上で行われるので、このネットワークをまたぐすべてのTCPパケットのサイズを記録すればよい。具体的には、tcpdumpに以下のオプションをつけて実行した。取得するパケットは二つの条件でフィルターをかけた。
\begin{itemize}
\item {\tt src net 10.20.0.0/16}\\
このフィルターにより、指定したデバイスを経由したパケットのうち、送信元が10.20.0.0/16のネットワークであるパケットのみが取得する。つまり、これで、このネットワーク以外のパケットを取得しないことになる。この条件で、余計なARPクエリなどを弾ける。
\item  {\tt dst net 10.20.(マシン番号).0/24}\\
このフィルターにより、指定したデバイスを経由したパケットのうち、受信元が10.20.(マシン番号).0/16のネットワークであるパケットのみが取得できる。つまり、tcpdumpを実行するマシンで実行するCassandraノード宛のパケットだけを取得することができる。
\end{itemize}
この２つの条件により、他のマシンで起動しているCassandraノードからこのマシンで起動しているCassandraに送られてくるパケットだけを取得できるのである。

\item 同じマシン上で動作しているCassandraノード同士の通信は取得できない。\\
一方、tcpdumpで測定する方法では同じマシン上で動作しているCassandraノード同士の通信は取得できないことに留意したい。
\end{itemize}

\subsection{通信量の推定}
\subsubsection{実験1:gossipの通信量の推定}
tcpdumpを使用した上のような計測方法では、同じマシン上でのCassandraNode同士の通信を計測することはできない。そこで我々は下の仮定をもとに、計測した総通信量からCassandraノードで発生する総通信量を推測することにした。
\begin{itemize}
\item 仮定:任意のCassandra Node同士の通信量は平均すると同じである。
\end{itemize}
$n$台の各マシンで$m$台のcassandraノードを起動したとする。つまり、システム全体で合計$n*m$台のCassandraノードが起動されている。各マシンでtcpdumpを使用して計測した得られたトラフィックの合計を$Tt$とし、Cassandraノードで発生する通信量$T$とく。$Tt$は、$(n -1)*m$ノードのCassandraから取得した通信量であるので、上の仮定を用いると、$n * m$台のcassandraノードで発生する通信量$T$は、
\begin{equation}
T = Tt * (n * m ) / ((n-1) * m ) = Tt * n / (n-1)
\end{equation}
とCassandraノードで発生するgossipの総通信量を推測することができた。

\subsubsection{実験2:データ読み書きの通信量の推定}
非集中のクラウドストレージであるCassandraにおいてのデータ読み書き時の通信手順を説明する。クライアントと直接データの受け渡しを行うCassandraノードをproxyノードと呼ぶ。書き込み時には、proxyノードから担当ノードへデータが転送され、担当ノードはproxyにデータ書き込みが成功したことを知らせる、いわゆるAckを返す。読込時には、proxyノードが担当ノードに読み込みリクエストを転送し、受信した担当ノードがデータを転送する。

つまり、データ読み書きがある場合に発生する通信の種類は、データの転送、データ書き込み成功のAck,読み込みのリクエスト、そしてgossipによる通信の4つである。実験１でgossipプロトコルの通信量は測定できているので、計測した通信量から実験１の通信量を差し引くことで推定ができる。
%YCSBのクライアントは、Cassandra１ノードだけと接続して(これをproxyノードという。)データの読み書きを行う。データの書き込み、読み込み時のCassandraノード間での通信の流れを説明する。また今回はレプリカを作成していない。書き込み時には、proxyノードから担当ノードへデータが転送され、担当ノードはproxyにデータ書き込みが成功したことをしらせる。いわゆるAckを返す。読込時には、proxyノードが担当ノードに読み込みリクエストを転送し、受信した担当ノードがデータを転送する。つまり、データ読み書きが発生する問に
%データ通信量の推定について説明する。　データ通信量の推定値Tは、proxyノードが動作するマシンで取得した通信量をTA,proxyノードが動作するマシンで取得した通信量をTBとして、
%\begin{equation}
%T = ( TA + TB ) * (n-1) /n * m /  (m-1)
%\end{equation}
%で得られる。その理由を説明する。



\subsection{実験環境}
以下に実験環境を示す。
\begin{itemize}
\item Cassandra 0.6.6	
\item OS Linux	 2.6.35.10 74.fc14.x86\_64
\item CPU: 2.40 GHz Xeon E5620 × 2
\item JVM: Java SE 6 Update 21
\item Memory: 32GB RAM
\item Network: 1000BASE-T
\end{itemize}

\section{実験・評価}

\subsection{実験1:gossipの通信量}
図2が、10 秒あたりのマシン間の総通信量の変化をノード数別に表したグラフであ る。(ただし、1M =$10^6$,1K=$10^3$ とする。)ノードの台数によらず、100 秒以降は通信量 が安定していることがわかる。図3 は、ノード数と通信量が安定して いる時の(ここでは、実験開始から 200-300 秒 後とした)1 秒あたりの通信量の平均をプロッ トしたものである。
\begin{figure}[tb]
  \begin{center}
  \includegraphics[bb=0 0 504 450 ,width=8cm]{img/time-node-black.png}
  \caption{ノード台数別通信量の時間変化}
  \label{fig:javassist}
    \end{center}
\end{figure}


\begin{figure}[tb]
  \begin{center}
  \includegraphics[bb=0 0 504 450 ,width=8cm]{img/node-traffic.png}
  \caption{ノード台数に応じた通信量の増加}
  \label{fig:javassist}
    \end{center}
\end{figure}

\subsection{実験2:データ読み書きの通信量の測定}
図4は、YCSBを実行したときにデータ読み書きで発生した通信量をノード台数別に表したグラフである。ただし、QPS($queries/s$)は1000で一定であり、更新時のデータサイズは、1kbyteで行為してある。 
\begin{figure}[tb]
  \begin{center}
  \includegraphics[bb=0 0 504 450 ,width=8cm]{img/ycsb-node-traffic.png}
  \caption{ノード台数に応じたデータ読み書きの通信量の変化}
  \label{fig:javassist}
    \end{center}
\end{figure}


	
\subsection{評価}
\subsubsection{総通信量の見積もり}
図1の曲線は、プロット した点から二次関数でフィッティングしたも のである。$n $をノードの台数として得られた関数は、通信量($bit/s$)を$T$として
\begin{eqnarray}
T &=& 224.6*n^2+ 4314.8*n
\end{eqnarray}
  である。よって、通信量は O($n^2$)でスケール することがわかった。	この関数から、ノード台数をパラメータとし て Cassandra の gossipプロトコル で発生しうる全体の通信量を推測することができる。例えば、$n = 1000$のとき、[通信量]$ = 229Mbps$ と なる。このように、この関数を使って総通信量 が見積もることができる。また、クラスタの設 計時にも活かすことができる。
\subsubsection{１ノードあたりの通信量}
また同様に、１ノードあたりの通信量を見積もることも可能である。総通信量をCassandraノードの台数$n$で割った値が、１ノードあたりの通信量$T'$となる。つまり、
\begin{eqnarray}
	T' &= & (224.6*n^2+ 4314.8*n) / n\\
	&=& 224.6*n+ 4314.8
\end{eqnarray}
とO(n)でスケールすることがわかる。
%グラフに示すと以下になる。
%X軸がノード台数、Y軸が通信量である。また、この通信量はメンバーシップ管理で受信、送信する通信量のそれぞれの値である。
\if0
\subsubsection{システム全体の限界とは？}
以上より総通信量はある関数に沿って、スケールしていることがわかった。この結果は、クラスタ設計時 に活かすことができる。つまり、クラスタを構成するノード数に応じて、どの機器でどれくらいの通信量が発生するかを見積もることができる。一般的には議論するのは難しいので、クラスタの構成ごとに具体的なケースに商店を当てて見ていく。\\
\fi
\subsubsection{gossipの通信量がO($n^2$)でスケールしていく理由}
gossipの通信量がO($n^2$)でスケールしていく理由について考察する。
総通信量$T$($bit/s$)は、１ノードあたりの通信量($bit/s$)を$T'$、ノード台数を$n$として、
  \begin{equation}
  T = T' * n 
 \end{equation}
である。さらに１秒毎のgossip通信が行われる回数を$s$,１回のgossip通信にかかる通信量$tg$($bit$)として、１ノードあたりの通信量$T'$($bit/s$)は、
\begin{eqnarray}
 T' &=&  s * tg
\end{eqnarray}
となる。メンバー構成が安定した時を考える。Cassandraのメンバー管理シップでは、メンバー構成が安定したときは、毎秒1-2回のgossip通信が行われる。
よって１秒毎のgossip通信する回数$s$は、
\begin{eqnarray}
 s < 2 = Order(Const)
\end{eqnarray}
 一方、1回あたりのgossip通信の通信量$tg(bit)$はScuttlebuttのアルゴリズムから安定時にはノード台数に依存するので、
  \begin{equation}
   tg = Order(n)
    \end{equation}
よって式(5)より、１台あたりの通信量$T'(bit/s)$、 総通信量$T(bit/s)$は、
\begin{eqnarray}
T' &=& O(n)\\
T &=& Order(n^2)
\end{eqnarray}
となることが証明できた。また上記にCassandra固有の方式はほとんどない。よって、メンバー構成が安定した時のgossip baseのメンバーシップ管理アルゴリズムの通信量のスケーラビリティが評価できたことになる。
\subsubsection{データ読み書きの通信量はノード数}
グラフ図4から、QPSを一定にしたときに、構成するCassandraノード台数$n$に応じて、増加しないことが確認できた。これは直感的に明らかである。ノード台数が$n$台の時、クライアントとやり取りを行うproxyノードがデータを保持する担当のノードである確率は、$1/n$である。つまり、クライアントが要求するデータに対して、$(n-1)/n$の確率で通信が発生するのである。$n$sが大きくなると、その確率は1に近づいていくため、通信量はノード台数$n$に対して増加しないのである。


\section{まとめ}
本論では、gossipプロトコル を用いる Cassandra を対象として、 ノード台数に応じてシステム全体の通信負荷がどのように変化するのかを計測・考察した。計測の結果、システム全体で発生する通信量は、ノード 台数を$n$としたときO($n^2$) となることが確認でき、定量的にクラウドストレージのgossipベースのメンバーシップに要する通信量を計測することができた。今後の課題について2つ記す。

１つ目は、クラウドストレージにおけるgossipプロトコルを別の切り口から検討していくことである。故障検知アルゴリズム評価は、通信量という切り口のほかにもCPU占有率や故障の伝搬スピードなどが挙げられる。それらの評価を非集中なクラウドストレージで行う。

２つ目は、gossipプロトコル以外の故障検知アルゴリズムを評価し、比較することである。
gossip以外の故障検知アルゴリズムには、情報を更新するとすべてのメンバーに全対全で情報を伝搬していくアルゴリズムや、近傍にだけ更新を伝えるアルゴリズムなどがある。これらを評価し、比較することでgossipの性能を他のアルゴリズムと比較しながら評価できる。

\begin{acknowledgment}
本研究は科研費（22680005）の助成を受けたものである. 
\end{acknowledgment}

\if0
\begin{thebibliography}{10}

\bibitem{total}
Avinash Lakchman and Prashant Malik: Cassandra -A Decentralized Structured Storage System, Proc LADIS ’09, 2009

\bibitem{total}
Giuseppe de CandiaLA, Deniz Hastorun, Madan Jampani, Gunavardhan Kakulapati, Avinash Lakchman, Alex Pilchin, Swaminathan Sivasubramanian, Peter Vosshall, and Werner Vogels:
Dynamo:	Amazon’s	Highly Available Key-value Store, SOSP '07, 2007.

\bibitem{total}
Robbert van Renesse, Dan Dumitriu, Valient Gough, Chris Thomas and Amazon.com, SeattleEfficient Reconciliation and Flow Control for Anti-Entropy,LADIS ’08, 2008.

\bibitem{total}
Marcia Pasin,St'phane Fontaine,Sara Bouchenak: Failure Detection in Large Scale Systems: a Survey,  NOMS Workshops ’08, 2008.

\bibitem{total}
Miguel Matos,Ant\'onio Sousa,Jose Pereira,Rui Oliveira,Eric Deliot,Paul Murray: CLON: Overlay Networks and Gossip Protocols for Cloud Environments,  NOMS Workshops ’08, 2008.

\bibitem{total}
丸山不二夫,首藤一幸: クラウドの技術, ASCII pp.6--13
  
 \bibitem{Web}
Cassandra Wiki, http://wiki.apache.org/cassandra/
\end{thebibliography}
\fi

\bibliography{sacsis}
\end{document}
