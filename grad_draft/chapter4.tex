%%%%
\chapter{gossipプロトコル}
本研究の主な対象であるgossipプロトコルについて詳しく説明する。まず、故障検知におけるgossipプロトコルの位置づけを整理する。次に、gossipプロトコルをベースにした情報共有プロトコルであるScuttlebuttについて説明する。
\section{故障検知とは}
以下論文 \cite{Survey}で述べられている故障検知の定義と分類基準について紹介する。
まず、故障検知の定義を述べる。故障検知とは故障しているノードについての情報を集めるプロセスのことであり、故障が疑わしきノードと、モニターしているノードのリストを管理している。リストは、スタティック、ダイナミックの二つがあり得る。ダイナミックなリストは、絶えず変化するノード群を管理していていることである。ネットワークの激しい変化に対しての対応能力を考慮すると、もっと現実的なモデルといえる。一方でスタティックなリストは予め決められたノードだけを管理する。

故障検知はハートビートとPingの２種類の生存確認メッセージを使って、故障しているノードを判断する。
%キープアライブ == 生存確認メッセージ
\begin{itemize}
\item ハートビート\\
ハートビートは、モニターしているプロセスから故障検知を行うプロセスに定期的に送られてくるメッセージのことである。
このメッセージで対象ノードが故障していないことを知らせる。
もしハートビートが制限時間内に届かなければ、故障検知を行うプロセスは故障していると判断する。
\item Ping\\
Pingは、故障検知を行うプロセスからモニターしているノードに継続的に送られるメッセージのことである。
故障検知を行うプロセスは、その応答としてAckを受け取る準備をしている。
もしAckを受け取れなければ、一定時間ごとにメッセージを送るなどで精密な調査を行い、プロセスが本当に故障しているかどうかを確かる。
\end{itemize}


実際はメッセージ到達の遅延は予測することはできないので、非同期的な環境下で故障しているノードと健全なノードを見分けるのは困難である。
よって、故障検知の問い合わせに対して返答がないプロセスは「故障が疑わしきもの」として扱われる。

次に、大規模環境での故障検知を分類するための基準を考える。以下のような分類の切り口が挙げられる。
\begin{itemize}
\item A.集中型 vs. 分散型
\item Pull型 vs. Push型
\item C.アクティブ vs. パッシブ
\item D.ベースライン vs. シェアリング
\item E.適応可能な値 vs. 一定の値
\item F.グローバル時刻 vs. ローカル時刻
\item G.モニターパターン
\item H.故障の伝搬
\end{itemize}

\paragraph{A.集中型 vs. 分散型}
集中型の故障検知は、単体で一枚岩的なモジュールであり、様々なプロセスをモニターすることが可能である。
集中型の長所は管理コストが低いこと、欠点は単一故障点が存在し、潜在的なボトルネックとなりやすいことである。
一方で分散型の特徴は、これらの欠点がない。
分散型は、一連の故障検知モジュール群とみなされていて、各モジュールにシステムの中で異なるプロセスが割り当てられている。
リクエストが来るとすぐに、各モジュールが故障が疑わしいノードのリストを提供する。
\paragraph{Pull型 vs. Push型}
生存確認メッセージの受け渡しに関して、Pull型とPush型の二つに分類できる。
Push型アプローチでは、ハートビートを用いており、制御フローと情報フローの方向は同じである。
一方、Pull型の故障検知はこのフローは逆である。
Pull型の故障検知においては、Pingメッセージが使われる。
ハートビートは、Ping故障検知と比較して半分のメッセージのやりとりしか必要ないこと、タイムアウト遅延の見積もりが片道のメッセージで判断が出来ることから、アドバンテージがあると考えられる。
Ping故障検知のアドバンテージの一つは、時間の制御が故障検知をおこなうプロセスにおいてだけ実行されることである。


\paragraph{C.アクティブ vs. パッシブ}
情報を伝搬する際にアプリケーションを利用するかどうかで故障検知を分類できる。
アクティブなプロトコルは、生存確認メッセージを継続して送信、受信する。
パッシブなプロトコルは、アプリケーションメッセージを利用して故障検知を行う。
もしデータ通信が頻繁に発生するならば、故障検知は十分であると言える。
一方でパッシブプロトコルが適切でない状況もあり、そうした状況ではアクティブなプロトコルが必要になる。
\paragraph{D.ベースライン vs. シェアリング}
ノードの生存情報について共有するかどうかに関して、ベースラインとシェアリングの二つに分類できる。
シェアリングアプローチでは、故障検知するモジュールはモニターしているノードの生存情報について他のモジュールと共有する。
ネットワークトポロージを考慮して、概して近隣ノード群が使われる。
シェアリングアルゴリズムでは、交換される情報の種類、これらが維持する生存確認状態の分量において異なる。
ベースラインアプローチでは、それぞれのモジュールが独断で故障が疑われるノードについて判断を下す。
\paragraph{E.適応可能な値 vs. 固定の値}
生存確認メッセージの頻度、タイムアウト、その他の時間についての設定を、適応可能な値にするか、固定の値にするかで分類できる。
固定の値を採用する利点は、例えば、ノードがシステムに参加したときなどに一度各ノードで計算されるだけであるので実装が容易である。
欠点は、ネットワークの激しい変化状況では、効率性は制限されてしまうことである。
適応型の故障検知では例えば、タイムアウトの値を調整することで、新しいハートビートの到着時間を予想する。
懸念は、こういった値やタイムアウトを計算することは、単純な仕事ではないことである。
またいくつかのネットワーク情報を考慮しなければならない。
\paragraph{F.グローバル時刻 vs. ローカル時刻}
時間に関するその他の事柄は、個々でおこなうか、グローバルに行うかである。
単純なアプローチは、すべてのノードに対して、グローバルに生存確認メッセージを出す頻度を利用することである。
もしすべてのノードが同質で、同じセッションの存在時間を設けているならばこのアプローチは効果的である。
一方、もしノードが同質でないときは、個々のノードがそれぞれがローカル時刻を計算することになる。

その他の分類基準を紹介する前に、我々は大規模環境での故障検知の３つの大きなオペレーション「正常」、「伝搬」、「再設定」について説明する。
\begin{itemize}
\item 正常\\
「正常」フェーズで、故障検知モジュールは生存確認メッセージをモニターするノードに送信する。
\item 伝搬\\
故障が検知されたときに「伝搬」フェーズがスタートし、故障情報がその他のモジュールに伝えられる。
\item 再構成\\
「再構成」フェーズは「伝搬」フェーズが終了したときにスタートする。
「再構成」フェーズは、ローカルの「再構成」とグローバルの「再構成」の二つフェーズからなる。
ローカルの「再構成」は、現存モジュールの故障を修理するときに起きる。
例えば、修理が完了するまでグループからこのノードを取り除くことができる。
グローバルの「再構成」は、故障情報が他のモジュールに伝搬されたときに起きる。
このオペレーションで、他のノードはシステム情報の変化を反映させることができる。
\end{itemize}
大規模分散環境での故障検知では、モニタリングと伝搬パターンについて二つのパフォーマス問題が存在する。
迅速な伝搬は、システムの整合性を維持するのにつながり、効率的なモニターリングは検知時間を短縮する。

\paragraph{G.モニターパターン}
モニタリングのパターンは、「正常」フェーズにおける故障検知モジュールとモニターしているノードにおけるコミュニケーションに関連がある。
モニタリングのパターンには、全対全型、ランダム型、近接ベース型の３つがある。
\begin{itemize}
\item 全対全型\\
全対全型の故障検知では、各モジュールがすべてのモニターしているプロセスに生存確認メッセージを送信する。
構成するグループのメンバーが少ない時、このアプローチは、効率的に機能する。
一方で、スケーラビリティは制約される。
プロセス数が膨れ上がった時には、大規模ネットワークトラフィックが発生するからである。
\item ランダム型\\
ランダム型の故障検知では、各メンバごとに故障検知に使用するためのアドレスと時間のリストを管理している。
グループ内の各ノードは、ランダムに他のｋノードを選択して、生存確認メッセージを送信する。\\
gossipプロトコルはハートビートをもとにランダムで故障検知を行う。
gossipプロトコルはグループ数が少ないときにはとても効率的である。大規模分散環境のようなグループ数が多い状況をでは、様々なバリエーションの故障検知が提案されている。
大規模分散環境におけるgossipプロトコルについては、故障検知の分類の後に説明する。
モニターしているノード同士でランダムであるいは定期的なコミュニケーションを通じて行われるランダム型の故障検知では、スケーラビリティの改善、検知時間の短縮が可能である。
また故障検知時間は、ランダムに選択される確率に依存する。
\item 近接ベース型\\
各プロセスは生存確認メッセージを近隣ノードに送る。
局所性を考慮した通信を行うことで、パフォーマンスが改善される。
近隣ノードは、故障を検知しない限り時間が経過しても静的で変化しない。
一方故障を検知した場合には、故障したノードを除いたり新しい近隣ノードを選択するために「再構成」フェーズが必要になる。
またネットワーク情報は考慮されなければならない。
\end{itemize}
\paragraph{H.故障の伝搬}
あるノードが故障していると判断されたとき、この情報は他のモジュールに伝搬されなければならない。
故障の伝搬は、規模環境では非常に時間がかかるもので、伝搬にかかる時間を短縮するためにさまざまなアプローチが提案されている。
全対全、ランダム、リング状の空間、階層構造がある。
\begin{itemize}
\item 全対全型の伝搬パターン\\
全対全型の伝搬パターンの場合、故障は瞬時にすべての故障検知モジュールに伝わる。
もし故障やチャーンが頻繁に起こるならば、ネットワーク通信量が一気に跳ね上がってしまう。
%この場合の故障検知の実装は、パフォーマンスの理由からIPマルチキャストを利用するのがよいだろう。
\item ランダム型の伝搬パターン\\
ランダム型の伝搬パターンでは、モジュール、モジュール群が選択されて、現存する故障検知モジュールから故障についての情報を受け取る。
利点は、全対全伝搬パターンに比べて通信が少なくて済むことである。一方、欠点は伝搬にかかる時間が別のノードに選択される割合に依存してしまうことである。
\item 円形状の空間の伝搬パターン\\
円形状の空間の故障検知では、仮想的なリングにノード群を配列する。
通信は、近接するノード群だけで行われる。
欠点としては、新しいノードが追加されたり、リングからノードが離脱したときには、近接ノードは再構成されなければならないことである。
また、仮想的なネットワークトポロジに対して、仮想的なリングをマッピングするのは容易なことではない。
また大きなリングにおいて故障の伝搬に非常に時間がかかる。
\item 階層構造型の伝搬パターン\\
階層的な故障検知では、ノード群を複数の階層に配列し、少ないグループのモニタリングに分断する。
利点としては、ツリーにそって故障が伝搬していくために、スケーラビリティが改善されることである。
また、ネットワークのインフラ事情を考慮に入れることができるので、通信が効率的である。
階層的な故障検知は、一般的に大規模分散システムにおいて用いられていおり、他の伝搬パターンで動作しているスモールグループ同士を連結している。
\end{itemize}

このような分類基準で故障検知を分類することが可能である。また故障検知におけるgossipプロトコルの位置づけを整理できた。





\if0
さらに論文では、故障検知のQoS指標について述べている。大規模環境における故障検知のQoSは、
一貫性、パフォーマンス、ダイナミックな環境に対する適応、スケーラビリティと関連している。

\begin{itemize}
\item 一貫性についての指標\\
(TODO:意味ブー)
故障検知は正確性と完全性という二つの主な分類可能な性質がある。正確性は、故障検知が犯すミスに言及していて、完全性は故障検知が最終的にノードが故障していると疑うことに言及している。故障検知のQos仕様のための主な指標と推論の正確性の指標を提案している。
完全性に関連している主な指標は、検知するまでの時間と故障検知にかかる時間である。
正解性と関連している二つの指標は、ミスの再発性、ミスが発生し続けている期間である。
推論される正解性の指標は、平均ミス率、クエリーの正確性の確率、よいレスポンスタイム、良い転送タイム？


\item パフォーマンスについての指標\\
 パフォーマンスの指標は、故障検知によって使われるリソース(ノード、ネットワークなど)と関連がある。主な指標は、CPUロード、メモリー消費、ネットワークバンド幅である。故障検知は、これらのリソースの消費を制限するかもしれないし、増加させるかもしれない。例えば、バンド幅の消費を減らすために、故障検知は、ネットワーク越しに送るメッセージ数を制限するかもしれない。
パフォーマンス指標は、故障検知が影響をあたえることができない(つまり、間接的に影響を与える)事柄もふくんでいる。これらの指標には、ノード故障率、ノード故障までの時間、平均復帰時間、平均故障間隔、平均ノード生存時間、また、遅延、メッセージロス、リンク故障率、リンク故障までの時間などのネットワークの振る舞いにも関連している。
\item ダイナミックな環境に対する適応についての指標\\
このカテゴリーは、故障検知がダイナミックなシステムの振る舞い(変化)に対応する能力に関連する指標を包含している。大規模環境の故障検知では、高いチャーン率、爆発的なメッセージ数の増加、メッセージロス、ヘテロな環境、柔軟性に適応できなければならない。適応性に関する指標は、ダイナミズム関連と、柔軟性に関連する指標の二つのグループに分類される。ネットワークダイナミズムに関連する指標は、故障検知が直接影響を及ぼせないようなパフォーマンス関連の指標に記述されている。フレキシビリティについての指標は、グローバルなあるいはローカルのkeep-aliveメッセージの割合、一定or変化するkeep-aliveメッセージの割合である。

\item スケーラビリティについての指標\\
スケーラビリティは、少なくとも以下に挙げる指標のうちの一つから定義される。
サイズスケーラビリティ、地理的なスケーラビリティ。スケーラビリティについての指標には、グループサイズや遅延が含まれている。
\end{itemize}

さらにこの指標と分類に基づいて、大規模分散環境のための主な故障検知ソリューションをいくつか挙げている。

\begin{itemize}
\item 生存情報を共有して、検知時間を改善する\\
故障検知時間は、近隣ノード間で生存情報を共有することで改善される。つまり、最初に故障を検知したノードが他のノードにアナウンスするのである。ある論文では、ネットワーク上の2000ノードで実験していみたところ、近隣のノードの数は増加するにもかかわらず、検知時間はほとんど変わらなかった。そこで、著者は、情報共有することで、高いチャーン率に適応するのを助けることができると主張する。
\item 適応性についてのソリューション\\
\item 
\item 
\item 
\item 
\end{itemize}

\fi


\section{大規模分散環境におけるgossip プロトコル}
次に、大規模分散環境でのgossipプロトコルの応用について考える。
グループ数が少ない時の単純なgossipプロトコルを大規模環境で利用することは、伝搬時間の遅延、通信量の増加などの理由から適切ではなく、改善されなければならない。
とくに故障情報の伝播方法に焦点が当てられている。

単純なgossipプロトコルではハートビートで自身の生存を他のノードに知らせているが、ハートビートの際に、他のノードの生存情報を伝播することもできる。
この方法には３種類の方法がある。ノード$P$とノード$Q$の情報伝播について考える。
\begin{itemize}
\item Push型(図\ref{fig:gossip_pls}:左)\\
Push型では、ノード$P$が持っている情報をノードに知らせノード$Q$の情報を更新する。
つまりノードPの更新情報がハートビートとなるのである。
\item Pull型(図\ref{fig:gossip_pls}:中)\\
Pull型はPush型の逆で、ノード$Q$が持っている情報を引き出しノード$P$の情報を更新する。
つまり、ノード$Q$へのリクエストがハートビートとなっている。
またノード$Q$へのリクエストの内容をノード$P$のもつ情報のタイムスタンプだけ (ダイジェストと呼ぶ) を送信することでノード$Q$からノード$P$へのデータ量を削減することができる。

\item Pull\&Push型(図\ref{fig:gossip_pls}:右)\\
Pull\&Push型はPull型と同様である。違いは、ノード$Q$からノード$P$へ更新情報を送信する際に
ノード$Q$のダイジェストも添付しておくことである。その後ノード$P$からノード$Q$へ情報が更新される。

\end{itemize}
このようにハートビートと情報伝播を同時に行うことで伝搬時間の遅延の抑制、通信量の削減が可能である。
\if0
・全対全でリストを保持
・ランダムに伝搬していく
\fi

\begin{figure*}[t]
 \begin{center}
\includegraphics[bb=0 0 900 200 ,width=14cm,scale=2]{img/gossip_gray.png}
\caption{gossipプロトコル}
\label{fig:gossip_pls}
 \end{center}
\end{figure*}

\section{Scuttlebutt}
クラウドストレージにおける故障検知はメインタスクではない。
そこで、故障検知におけるCPUサイクル、ネットワーク帯域幅の消費はできるかぎり抑えなければならない。
そのようなリソース消費を抑えた情報共有プロトコルであるScuttlebutt \cite{EfficientReconciliationan}について詳しく説明する。
ScuttlebuttはPull\&Push型gossipプロトコルを応用したプロトコルである。

これまではノード$A$の故障情報というように、ノード$A$をキーにして故障しているかどうかの値を定めていた。
しかしScuttlebuttではさらに一般的に議論していて、Aというキーの下に、キーバリューのペアを複数もつことを想定している。
各メンバーそれぞれがもつ情報を、システム全体として整合性を保ちつつ、融合していく方法について言及している。
Scuttlebuttではメンバー同士でやりとりする情報に制約をかけることで、システム全体の整合性を保ちつつ、CPUやメモリーなどのリソースの消費を押さえることができる。


Scuttlebuttとは、分散システムで結果整合性モデルで各メンバーが保持する情報を融合をするためのプロトコルの一つである。
結果整合性とは、システムに一時的に整合性が取れていない状態が生まれても、ある期間の後には整合性がとれた状態になることが保証されていることである。
例えば、DNSシステムなどである。 \cite{TC}
Pull\&Push型アプローチを採用している。
特に、使用できるネットワーク帯域幅、CPUサイクルが限定されているときを想定している。
つまり、使用するネットワーク帯域幅を抑えるためにあるMTU (Message Transfer Unit) が決められていると仮定して、MTUのサイズ内で情報を融合できるように工夫し送信を行うのである。
具体的には、更新する情報に優先順位をつけて必要な情報だけを相手に伝搬させることで、システムの整合性を保ちつつ、ネットワーク帯域幅の消費を抑えた情報融合を可能にする。

通信手順について説明する。
メンバーの集合を$P = \{p, q, ...\}$とし、各メンバーがマッピング$\sigma \in S = K \rightarrow (V \times N)$にモデル化された状態を保持している。ここで、$K$はキーのセット、$V$は値のセット、$N$は有限の順序付けられたバージョン番号の集合を表している。
$\sigma(k) = (v,n)$は、キー$k$が値vと、バージョン番号$v$にマップすることを意味している。　また最近のマッピングほどバージョン番号が大きい。
メンバーの状態は変更があり、またすべてのノードで複製化され保持している状況を考える。
そこでノード$p$が保持する各メンバーのマッピングを$u_p$:P $\rightarrow$ $S$とモデル化する。

メンバーの状態の更新を考える。メンバー$p$は、$u_p(p)$に対する更新のみが行えて、$u_q(p), p \neq q$に対してはgossipを通じて間接的にしか更新することができない。
%gossipプロトコルでの更新には、マージ・融合オペレータである$ \Theta $を使用しS内の二つの状態から新しい状態を生み出す。 \sigma_1(k)= (v_1 ,  n_1)$のセマンティクスは、
Scuttlebuttにおいての$u_p(p)$に対する更新では、一度に一つのキーに対する更新のみが可能であり、更新したキーに対するバージョンは、$p$が保持するマッピングの中のバージョン($max(\sigma_p)$)よりも大きな値に更新する規則がある。メンバー$p$とメンバー$q$
における更新では、$u_p(r)$に対する更新つまり融合では、バージョンが大きいキーの値で更新される。
$\sigma_1(k) = (v_1, n_1)$と$\sigma_2(k) = (v_2, n_2)$が融合し、$\sigma$が生成されるとする。
$n_1 >  n_2$であれば$\sigma = (v_1, n_1)$、そうでなければ$\sigma = (v_2, n_2)$となる。
ここで、ある特定のメンバー$p$が持つキー$k$, 値$v$, バージョン$n$のタプルを$delta$を名付ける。
%アンチエントロピープロトコルは、マージ・融合オペレータである$ \Theta $を使用し、新しい状態を生み出す。$\sigma = \sigma_1 \Theta  \sigma_2$は以下を意味している。
%$ \sigma_1(k)= (v_1 ,  n_1)$
%キーに対する更新はあるキー$k$を更新する時は、二つのに対してバージョンが新しい値として更新後となる。

Scuttlebuttでは以下のように通信が行われる。
\begin{enumerate}
\item メンバー$p$が保持する各メンバーについてmappingの中で一番新しいバージョンだけ($\{(r, max(u_p(r))| r \in P )\}$)をメンバー$q$に送信する。
\item 同様に、メンバー$q$が保持する各メンバーについてmappingの中で一番新しいバージョンだけ($\{(r, max(u_q(r))| r \in Q )\}$)をメンバー$p$に送信する。
\item 上のようなダイジェストを受信したメンバー$q$は、下で定義している$\Delta^{p \rightarrow q} _{scuttle}$をメンバー$q$に送信する。
\item 3.と同様に、メンバーpから$\Delta^{q \rightarrow p} _{scuttle}$をメンバー$p$に送信する。
\begin{eqnarray}
\Delta^{p \rightarrow q} _{scuttle} = \{(r, k, v, n) | u_p(r)(k) = (v, n)\nonumber \\
\land   n > max(u_q(r)))\}\nonumber
\end{eqnarray}
すなわち、$\Delta^{p \rightarrow q} _{scuttle} = \{(r, k, v, n) | u_p(r)(k) = (v, n)$とは、あるメンバｒについてメンバー$q$がまだ更新していないキーの$delta$ということである。
\end{enumerate}
このようにはじめに、各メンバーに対する最大のバージョン番号をダイジェストとして通信することで、無駄な通信を省略することができる。
さらにMTUが存在するときには、手順3.手順4.ですべての更新情報を送信することはできない。
そこでバージョンが小さい$deltas$に優先順位をつけて更新の選択を決定することになる。
この選択により、システムの整合性を保ちつつ効率的な通信が可能になる。



